{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment #4: Extracting syntactic groups using recurrent networks\n",
    "Author: Pierre Nugues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will create a system to extract syntactic groups from a text. You will apply it to the CoNLL 2000 dataset. You will train your models with PyTorch.\n",
    "\n",
    "Be aware that in PyTorch, the data matrices, by default, have an unconventional ordering with recurrent networks. To have a batch ordering similar to what we saw during the course, you must use the `batch_first=True` argument. See here https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_sequence.html and https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
    "\n",
    "Before you start the assignment, please run the prerequisites from the prerequistites notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objectives of this assignment are to:\n",
    "* Write a program to detect partial syntactic structures called groups or chunks\n",
    "* Understand the principles of supervised machine learning techniques applied to language processing\n",
    "* Write a short report of 2 to 3 pages on the assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This instruction may solve installation conflicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import conlleval\n",
    "import math \n",
    "import functools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeds\n",
    "Making things reproduceable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x257a7c31c70>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "np.random.seed(1234)\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "LSTM_HIDDEN_DIM = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to adjust the paths to load the datasets from your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'corpus/train.txt'\n",
    "test_file = 'corpus/test.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now convert the dataset in a Python data structure. Read the functions below to load the datasets. They store the corpus in a list of sentences. Each sentence is a list of rows, where each row is a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sentences(file):\n",
    "    \"\"\"\n",
    "    Creates a list of sentences from the corpus\n",
    "    Each sentence is a string\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    f = open(file).read().strip()\n",
    "    sentences = f.split('\\n\\n')\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_rows(sentences, column_names):\n",
    "    \"\"\"\n",
    "    Creates a list of sentence where each sentence is a list of lines\n",
    "    Each line is a dictionary of columns\n",
    "    :param sentences:\n",
    "    :param column_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    new_sentences = []\n",
    "    for sentence in sentences:\n",
    "        rows = sentence.split('\\n')\n",
    "        sentence = [dict(zip(column_names, row.split())) for row in rows]\n",
    "        new_sentences.append(sentence)\n",
    "    return new_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CoNLL 2000 files have three columns: The wordform, `form`, its part of speech, `pos`, and the tag denoting the syntactic group also called the chunk tag, `chunk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['form', 'pos', 'chunk']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the corpus as a list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'form': 'He', 'pos': 'PRP', 'chunk': 'B-NP'},\n",
       "  {'form': 'reckons', 'pos': 'VBZ', 'chunk': 'B-VP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'current', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'account', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'deficit', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'will', 'pos': 'MD', 'chunk': 'B-VP'},\n",
       "  {'form': 'narrow', 'pos': 'VB', 'chunk': 'I-VP'},\n",
       "  {'form': 'to', 'pos': 'TO', 'chunk': 'B-PP'},\n",
       "  {'form': 'only', 'pos': 'RB', 'chunk': 'B-NP'},\n",
       "  {'form': '#', 'pos': '#', 'chunk': 'I-NP'},\n",
       "  {'form': '1.8', 'pos': 'CD', 'chunk': 'I-NP'},\n",
       "  {'form': 'billion', 'pos': 'CD', 'chunk': 'I-NP'},\n",
       "  {'form': 'in', 'pos': 'IN', 'chunk': 'B-PP'},\n",
       "  {'form': 'September', 'pos': 'NNP', 'chunk': 'B-NP'},\n",
       "  {'form': '.', 'pos': '.', 'chunk': 'O'}]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences = read_sentences(train_file)\n",
    "train_dict = split_rows(train_sentences, column_names)\n",
    "train_dict[10:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_file = 'corpus/glove.6B.100d.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the function below that reads GloVe embeddings and store them in a dictionary, where the keys will be the words and the values, the embedding vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_embeddings(file):\n",
    "    \"\"\"\n",
    "    Return the embeddings in the from of a dictionary\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    embeddings = {}\n",
    "    glove = open(file, encoding='utf8')\n",
    "    for line in glove:\n",
    "        values = line.strip().split()\n",
    "        word = values[0]\n",
    "        vector = np.array(values[1:], dtype='float32')\n",
    "        embeddings[word] = vector\n",
    "    glove.close()\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read the embeddings\n",
    "embeddings_dict = read_embeddings(embedding_file)\n",
    "embedded_words = sorted(list(embeddings_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# words in embedding dictionary: 400000'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'# words in embedding dictionary: {}'.format(len(embedded_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chording',\n",
       " 'chordoma',\n",
       " 'chordophones',\n",
       " 'chords',\n",
       " 'chore',\n",
       " 'chorea',\n",
       " 'chorene',\n",
       " 'choreograph',\n",
       " 'choreographed',\n",
       " 'choreographer']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_words[100000:100010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.51973,  1.0395 ,  0.20924,  0.16285,  0.7209 ,  0.81524,\n",
       "       -0.34641, -0.76654, -0.49576,  0.24634,  0.44094,  0.37701,\n",
       "       -0.16396,  0.2775 ,  0.16563,  0.43869, -1.0887 ,  0.12663,\n",
       "        0.66916,  0.3578 ], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dict['chords'][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a cosine similarity, write a `closest(target_word, embeddings, count=10)` that computes the 10 closest words to the words _table_, _france_, and _sweden_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest2(target_word, embeddings, count=10):\n",
    "  c_s = []\n",
    "  tar = embeddings[target_word]\n",
    "  tar_len = np.sqrt(np.sum(tar**2))\n",
    "  for word in embedded_words:\n",
    "    vec = embeddings[word]\n",
    "    dot = np.dot(vec,tar)\n",
    "    vec_len = np.sqrt(np.sum(vec**2))\n",
    "    c_s.append((word,dot/(vec_len*tar_len)))\n",
    "  c_s = sorted(c_s, key=lambda x: -x[1])[:count]\n",
    "  return [tup[0] for tup in c_s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['france',\n",
       " 'belgium',\n",
       " 'french',\n",
       " 'britain',\n",
       " 'spain',\n",
       " 'paris',\n",
       " 'germany',\n",
       " 'italy',\n",
       " 'europe',\n",
       " 'netherlands']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest2('france', embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sweden',\n",
       " 'denmark',\n",
       " 'norway',\n",
       " 'finland',\n",
       " 'netherlands',\n",
       " 'austria',\n",
       " 'switzerland',\n",
       " 'germany',\n",
       " 'swedish',\n",
       " 'belgium']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest2('sweden', embeddings_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the ${X}$ and ${Y}$ Lists of Symbols from the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each sentence, you will build an input sequence, $\\mathbf{x}$, corresponding to the words and an output one, $\\mathbf{y}$, corresponding to the chunk tags.\n",
    "\n",
    "Write a `build_sequences(corpus_dict, key_x='form', key_y='chunk', tolower=True)` function that, for each sentence, returns the $\\mathbf{x}$ and $\\mathbf{y}$ lists of symbols consisting of words and chunk tags. Set the words in lower case if `tolower` is true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the 11th sentence of the training set, you should have:<br/>\n",
    "`x = ['he',  'reckons',  'the',  'current',  'account',  'deficit',  'will',  'narrow',  'to',  'only',  '#',  '1.8',  'billion',  'in',  'september',  '.']`\n",
    "\n",
    "`y = ['B-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sequences(corpus_dict, key_x='form', key_y='pos', tolower=True):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for sentence in corpus_dict:\n",
    "      sen_x = []\n",
    "      sen_y = []\n",
    "      for word_dic in sentence:\n",
    "        word = word_dic[key_x]\n",
    "        if tolower:\n",
    "          word = word.lower()\n",
    "        sen_x.append(word)\n",
    "        sen_y.append(word_dic[key_y])\n",
    "      X.append(sen_x)\n",
    "      Y.append(sen_y)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_symbs, Y_train_symbs = build_sequences(train_dict, key_x='form', key_y='chunk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', 'reckons', 'the', 'current', 'account', 'deficit', 'will', 'narrow', 'to', 'only', '#', '1.8', 'billion', 'in', 'september', '.']\n"
     ]
    }
   ],
   "source": [
    "print(X_train_symbs[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_symbs[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a vocabulary of all the words observed in the training set as well as in GloVe. You should find 401,464 different words. You will proceed in two steps.\n",
    "\n",
    "First extract the list of unique words `words` from the CoNLL training set and the list of chunk tags, `chunks`. You will sort them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = sorted(list(set(sum(X_train_symbs,[]))))\n",
    "chunks = sorted(list(set(sum(Y_train_symbs, []))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words seen in training corpus: 17258\n",
      "# Chunks tags seen: 22\n"
     ]
    }
   ],
   "source": [
    "print('# words seen in training corpus:', len(words))\n",
    "print('# Chunks tags seen:', len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['casinos',\n",
       " 'caspita',\n",
       " 'caspita-brand',\n",
       " 'cassettes',\n",
       " 'cast',\n",
       " 'castigated',\n",
       " 'castigating',\n",
       " 'castillo',\n",
       " 'casting',\n",
       " 'castro-medellin']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[4000:4010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-ADJP',\n",
       " 'B-ADVP',\n",
       " 'B-CONJP',\n",
       " 'B-INTJ',\n",
       " 'B-LST',\n",
       " 'B-NP',\n",
       " 'B-PP',\n",
       " 'B-PRT',\n",
       " 'B-SBAR',\n",
       " 'B-UCP']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, merge the list of unique CoNLL words with the words in the embeddings file. You will sort this list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_words = sorted(list(set(embedded_words+words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words in the vocabulary: embeddings and corpus: 401464\n"
     ]
    }
   ],
   "source": [
    "print('# words in the vocabulary: embeddings and corpus:', len(vocabulary_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joy',\n",
       " 'joya',\n",
       " 'joyal',\n",
       " 'joyandet',\n",
       " 'joyas',\n",
       " 'joyce',\n",
       " 'joycean',\n",
       " 'joycelyn',\n",
       " 'joyces',\n",
       " 'joydeep']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_words[200000:200010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the indices `word2idx`, `chunk2idx` and inverted indices `idx2word`, `idx2chunk` for the words and the chunk tags: i.e. you will associate each word with a number. You will use index 0 for the padding symbol and 1 for unknown words. This means that your first word will start at index 2. For the chunks, you will start at index 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word = {(i+2):vocabulary_words[i] for i in range(len(vocabulary_words))}\n",
    "idx2chunk = {(i+1):chunks[i] for i in range(len(chunks))}\n",
    "word2idx = {vocabulary_words[i]:(i+2) for i in range(len(vocabulary_words))}\n",
    "chunk2idx = {chunks[i]:(i+1) for i in range(len(chunks))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('!', 2), ('!!', 3), ('!!!', 4), ('!!!!', 5), ('!!!!!', 6), ('!?', 7), ('!?!', 8), ('\"', 9), ('#', 10), ('##', 11), ('###', 12), ('#a', 13), ('#aabccc', 14), ('#b', 15), ('#c', 16), ('#cc', 17), ('#ccc', 18), ('#cccccc', 19), ('#ccccff', 20), ('#d', 21), ('#daa', 22), ('#dcdcdc', 23), ('#e', 24), ('#f', 25), ('#faf', 26)]\n"
     ]
    }
   ],
   "source": [
    "print(list(word2idx.items())[:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chunk indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-ADJP': 1, 'B-ADVP': 2, 'B-CONJP': 3, 'B-INTJ': 4, 'B-LST': 5, 'B-NP': 6, 'B-PP': 7, 'B-PRT': 8, 'B-SBAR': 9, 'B-UCP': 10, 'B-VP': 11, 'I-ADJP': 12, 'I-ADVP': 13, 'I-CONJP': 14, 'I-INTJ': 15, 'I-NP': 16, 'I-PP': 17, 'I-PRT': 18, 'I-SBAR': 19, 'I-UCP': 20, 'I-VP': 21, 'O': 22}\n"
     ]
    }
   ],
   "source": [
    "print(chunk2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a numpy matrix of dimensions $(M, N)$, where $M$ will be the size of the vocabulary: The unique words in the training set and the words in GloVe, and $N$, the dimension of the embeddings.\n",
    "The padding symbol and the unknown word symbol will be part of the vocabulary at respectively index 0 and 1. \n",
    "\n",
    "Initialize the matrix with random values with the `np.random.uniform()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add two dimensions for the padding symbol at index 0 and unknown words at index 1\n",
    "embedding_matrix = np.random.uniform(-0.05, 0.05, (len(vocabulary_words) + 2, EMBEDDING_DIM))\n",
    "# embedding_matrix = np.random.random((len(vocabulary_words) + 2, EMBEDDING_DIM))\n",
    "# embedding_matrix = np.zeros((len(vocabulary_words) + 2, EMBEDDING_DIM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of your matrix is: (401466, 100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(401466, 100)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the matrix with the GloVe embeddings when available. This means: Replace the random vector with an embedding when available. You will use the indices from the previous section. You will call `out_of_embeddings` the list of words in CoNLL, but not in the embedding list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_of_embeddings = []\n",
    "temp = set(embedded_words)\n",
    "for word in vocabulary_words:\n",
    "  idx = word2idx[word]\n",
    "  if word in temp:\n",
    "    embedding_matrix[idx] = embeddings_dict[word]\n",
    "  else:\n",
    "    out_of_embeddings.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1464"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out_of_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"y'all\",\n",
       " 'yankus',\n",
       " 'year-ago',\n",
       " 'year-before',\n",
       " 'year-earlier',\n",
       " 'year-to-date',\n",
       " 'yield-management',\n",
       " 'zaishuo',\n",
       " 'zarett',\n",
       " 'zumbrunn']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_of_embeddings[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of the padding symbol, idx 0, random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03084805,  0.01221088, -0.00622723,  0.02853586,  0.02799758,\n",
       "       -0.02274074, -0.02235357,  0.03018722,  0.04581394,  0.03759326])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of the word _table_, the GloVe values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.61453998,  0.89692998,  0.56770998,  0.39102   , -0.22437   ,\n",
       "        0.49035001,  0.10868   ,  0.27410999, -0.23833001, -0.52152997])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[word2idx['table']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of _zarett_, a word in CoNLL 2000, but not in GloVe, random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04485961, -0.01950363,  0.03356147, -0.02404349, -0.04000838,\n",
       "        0.01959841, -0.03943566, -0.01355046,  0.00896135, -0.02441297])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[word2idx['zarett']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the ${X}$ and ${Y}$ Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now create the input and output sequences with numerical indices. First, convert the \n",
    "${X}_\\text{train\\_symbs}$ and ${Y}_\\text{train\\_symbs}$ \n",
    "lists of symbols in lists of numbers using the indices you created. Call them `X_train_idx` and `Y_train_idx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_idx = []\n",
    "Y_train_idx = []\n",
    "for x, y in zip(X_train_symbs, Y_train_symbs):\n",
    "  X_train_idx.append([word2idx[w] for w in x])\n",
    "  Y_train_idx.append([chunk2idx[c] for c in y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word indices of the three first sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[107701, 189360, 358640, 291209, 193879, 388606, 143496, 362305, 353285, 56501, 328878, 126632, 187522, 364843, 148777, 152124, 326524, 454, 131007, 152124, 306232, 363097, 454, 144953, 362305, 331257, 43426, 347508, 189267, 155109, 200552, 55175, 63614, 154, 259236, 120001, 873], [97171, 269136, 358640, 143112, 262191, 219534, 154, 307829, 106548, 362305, 43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204, 43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150, 873], [88319, 54890, 304156, 372747, 349558, 152124, 344283, 174855, 72318, 139858, 88675, 358640, 97171, 154, 144970, 362305, 56361, 57639, 261034, 288933, 240241, 189360, 180283, 234487, 183252, 340448, 218722, 360423, 873]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_idx[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chunk tag indices of the three first sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 7, 6, 16, 11, 21, 21, 21, 21, 6, 16, 16, 9, 6, 16, 7, 6, 22, 1, 7, 6, 6, 22, 11, 21, 21, 6, 16, 16, 7, 6, 16, 16, 6, 16, 16, 22], [22, 7, 6, 16, 6, 16, 6, 16, 16, 7, 6, 16, 16, 16, 11, 21, 21, 21, 6, 16, 7, 6, 7, 6, 16, 16, 22], [22, 6, 11, 6, 16, 7, 6, 11, 21, 21, 7, 6, 16, 6, 16, 11, 21, 6, 16, 16, 16, 7, 6, 16, 16, 16, 6, 16, 22]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_idx[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, pad the sentences using the `pad_sequences` function. After padding, the second sentence you look like (the indices are not necessarily the same).\n",
    "```\n",
    "x = [ 97171, 269136, 358640, 143112, 262191, 219534,    154, 307829, 106548,\n",
    "        362305,  43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204,\n",
    "         43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150,    873,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0]\n",
    "y = [22,  7,  6, 16,  6, 16,  6, 16, 16,  7,  6, 16, 16, 16, 11, 21, 21, 21,\n",
    "         6, 16,  7,  6,  7,  6, 16, 16, 22,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0]\n",
    "```\n",
    "\n",
    "You will call the results `X_train_padded` and `Y_train_padded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_idx = list(map(torch.LongTensor, X_train_idx))\n",
    "Y_train_idx = list(map(torch.LongTensor, Y_train_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_padded = pad_sequence(X_train_idx, batch_first=True)\n",
    "Y_train_padded = pad_sequence(Y_train_idx, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 97171, 269136, 358640, 143112, 262191, 219534,    154, 307829, 106548,\n",
       "        362305,  43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204,\n",
       "         43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150,    873,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_padded[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([22,  7,  6, 16,  6, 16,  6, 16, 16,  7,  6, 16, 16, 16, 11, 21, 21, 21,\n",
       "         6, 16,  7,  6,  7,  6, 16, 16, 22,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_padded[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your network consisting of one embedding layer, a simple recurrent neural network, either RNN or LSTM, and a linear layer. You will initialize the embedding layer with `embedding_matrix` using `from_pretrained()`. You may try other configurations after. As number of RNN/LSTM units use 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_matrix, embedding_dim, lstm_units, nbr_classes, bidi_lstm=False):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding.from_pretrained(torch.tensor(embedding_matrix).float(), freeze=True, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, lstm_units, num_layers=1, batch_first=True, bidirectional=bidi_lstm)\n",
    "        if not bidi_lstm:\n",
    "            self.fc = nn.Linear(lstm_units, nbr_classes)\n",
    "        else:\n",
    "            self.fc = nn.Linear(2*lstm_units, nbr_classes)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        lstm_out = F.relu(lstm_out)\n",
    "        logits = self.fc(lstm_out)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Model(embedding_matrix, EMBEDDING_DIM, LSTM_HIDDEN_DIM, len(chunks) + 1, bidi_lstm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (embeddings): Embedding(401466, 100, padding_idx=0)\n",
       "  (lstm): LSTM(100, 128, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=256, out_features=23, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the loss `loss_fn` and optimizer `optimizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = torch.optim.RMSprop(model1.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.LongTensor(X_train_padded)\n",
    "Y_train = torch.LongTensor(Y_train_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(X_train, Y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Few Experiments\n",
    "Flattening the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8936, 78])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 7, 6,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([697008])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.view(-1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred = model1(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8936, 78, 23])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_pred.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([697008, 23])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_pred.view(-1, Y_train_pred.size()[-1]).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a dictionary to store the accuracy and the loss. Th exact values are difficult to compute because of the padding symbols. We include the padding symbols in the computation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {}\n",
    "history['accuracy'] = []\n",
    "history['loss'] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:12<00:00, 22.05it/s]\n",
      "100%|██████████| 280/280 [00:13<00:00, 20.52it/s]\n",
      "100%|██████████| 280/280 [00:12<00:00, 22.24it/s]\n",
      "100%|██████████| 280/280 [00:12<00:00, 23.02it/s]\n",
      "100%|██████████| 280/280 [00:12<00:00, 22.97it/s]\n",
      "100%|██████████| 280/280 [00:12<00:00, 22.62it/s]\n",
      "100%|██████████| 280/280 [00:12<00:00, 22.99it/s]\n",
      "100%|██████████| 280/280 [00:12<00:00, 22.62it/s]\n",
      "100%|██████████| 280/280 [00:16<00:00, 16.59it/s]\n",
      "100%|██████████| 280/280 [00:11<00:00, 23.48it/s]\n",
      "100%|██████████| 280/280 [00:11<00:00, 23.43it/s]\n",
      "100%|██████████| 280/280 [00:11<00:00, 23.54it/s]\n",
      "100%|██████████| 280/280 [00:11<00:00, 23.38it/s]\n",
      "100%|██████████| 280/280 [00:11<00:00, 23.48it/s]\n",
      "100%|██████████| 280/280 [00:11<00:00, 23.44it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(15):\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "    word_cnt = 0\n",
    "    batch_cnt = 0\n",
    "    for X_batch, Y_batch in tqdm(dataloader):\n",
    "        batch_cnt += 1\n",
    "        Y_batch_pred = model1(X_batch)\n",
    "        loss = loss_fn(Y_batch_pred.view(-1, Y_batch_pred.shape[-1]), Y_batch.view(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_accuracy += torch.sum(torch.argmax(model1(X_train), dim=-1) == Y_train)\n",
    "    history['accuracy'] += [train_accuracy/torch.numel(Y_train)]\n",
    "    history['loss'] += [train_loss/batch_cnt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we visualize the training curves. Ideally, we would compare them with a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAGxCAYAAACa3EfLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABK+ElEQVR4nO3de1wU5eI/8M+6chVYU5GLIJKZIl4SLC6JlxIMlTT0iJaIt1MmdiTtV3rwQmphpzTs4q1jkpmE6WadpJS8QYe8RFimqJQol5YQzzdATJDl+f2xsbmwwC4i7A6f9+s1L9xnnpl5ZpjaD8/MPCMTQggQERERmbkObd0AIiIiopbAUENERESSwFBDREREksBQQ0RERJLAUENERESSwFBDREREksBQQ0RERJLAUENERESSwFBDREREksBQQ2RCZDKZQdPRo0fvaDtxcXGQyWTNWvbo0aMt0gZqPplMhri4uLZuBpHJkfE1CUSm4/jx4zqfV69ejSNHjuDw4cM65f3794eDg0Ozt1NQUICCggL4+/sbvWxZWRnOnTt3x22g5jt+/Djc3Nzg5ubW1k0hMikMNUQmbObMmdizZw+uX7/eaL0bN27A1ta2lVpFhvrjjz9gbW3d7F4xIjIOLz8RmZmRI0diwIABSEtLQ2BgIGxtbTF79mwAQHJyMkJCQuDi4gIbGxt4eXlhyZIlqKio0FmHvstPvXr1wvjx4/HVV1/Bx8cHNjY26NevH95//32devouP82cORN2dnb4+eefMXbsWNjZ2cHd3R2LFy9GZWWlzvIFBQWYPHky7O3t0blzZzz11FM4deoUZDIZEhMTG933q1evYv78+ejfvz/s7OzQvXt3PPLII0hPT69Xt7KyEqtWrYKXlxesra3RtWtXjBo1ChkZGdo6NTU1ePvtt/HAAw/AxsYGnTt3hr+/Pz7//HNtnYYu9fTq1QszZ87Ufk5MTIRMJsPBgwcxe/ZsODo6wtbWFpWVlfj5558xa9Ys9OnTB7a2tujRowfCwsJw5syZeuv9/fffsXjxYtx7772wsrJC9+7dMXbsWJw/f77RNhUVFeGZZ56Bm5sbLC0t4enpiZdffhnV1dU69TZt2oTBgwfDzs4O9vb26NevH/75z382etyJzEXHtm4AERlPpVJh+vTpePHFF/Hqq6+iQwfN3yc5OTkYO3YsYmJi0KlTJ5w/fx6vvfYaTp48We8Slj4//PADFi9ejCVLlsDJyQn//ve/MWfOHNx3330YPnx4o8veunULjz/+OObMmYPFixcjLS0Nq1evhkKhwIoVKwAAFRUVGDVqFP73v//htddew3333YevvvoKERERBu33//73PwDAypUr4ezsjOvXr+PTTz/FyJEjcejQIYwcORIAUF1djdDQUKSnpyMmJgaPPPIIqqurcfz4ceTl5SEwMBCAJozt3LkTc+bMwapVq2BpaYnvv/8ely9fNqg9+syePRvjxo3Dhx9+iIqKClhYWODXX39F165dsXbtWjg6OuJ///sfPvjgA/j5+SErKwt9+/YFAJSXl2PYsGG4fPkyXnrpJfj5+eH69etIS0uDSqVCv3799G6zqKgIDz30EDp06IAVK1agd+/e+Pbbb7FmzRpcvnwZ27dvBwB8/PHHmD9/Pp577jm88cYb6NChA37++WecO3eu2ftLZFIEEZmsqKgo0alTJ52yESNGCADi0KFDjS5bU1Mjbt26JY4dOyYAiB9++EE7b+XKlaLuf/4eHh7C2tpaXLlyRVv2xx9/iC5duohnnnlGW3bkyBEBQBw5ckSnnQDE7t27ddY5duxY0bdvX+3nd999VwAQX375pU69Z555RgAQ27dvb3Sf6qqurha3bt0Sjz76qHjiiSe05Tt27BAAxHvvvdfgsmlpaQKAiI2NbXQbAMTKlSvrlXt4eIioqCjt5+3btwsAYsaMGQa1u6qqSvTp00c8//zz2vJVq1YJACI1NdWoNj3zzDPCzs5O53cnhBBvvPGGACDOnj0rhBBiwYIFonPnzk22j8hc8fITkRm655578Mgjj9Qrv3TpEp588kk4OztDLpfDwsICI0aMAABkZ2c3ud4HHngAPXv21H62trbG/fffjytXrjS5rEwmQ1hYmE7ZoEGDdJY9duwY7O3t8dhjj+nUmzZtWpPrr7V582b4+PjA2toaHTt2hIWFBQ4dOqSzf19++SWsra21l+X0+fLLLwEA0dHRBm/bEJMmTapXVl1djVdffRX9+/eHpaUlOnbsCEtLS+Tk5NRr9/3334/Ro0cbtc0vvvgCo0aNgqurK6qrq7VTaGgoAM1xB4CHHnoIv//+O6ZNm4bPPvsMJSUld7CnRKaHoYbIDLm4uNQru379OoKCgnDixAmsWbMGR48exalTp6BUKgFoblptSteuXeuVWVlZGbSsra0trK2t6y178+ZN7edr167Bycmp3rL6yvRZv349nn32Wfj5+WHv3r04fvw4Tp06hccee0ynjVevXoWrq6v2spw+V69ehVwuh7Ozs0HbNpS+382iRYuwfPlyTJw4Ef/5z39w4sQJnDp1CoMHD67X7uY80fTbb7/hP//5DywsLHQmb29vANCGl8jISLz//vu4cuUKJk2ahO7du8PPzw+pqanN3Fsi08J7aojMkL6naQ4fPoxff/0VR48e1fbOAJobT01F165dcfLkyXrlRUVFBi2/c+dOjBw5Eps2bdIpLy8v1/ns6OiIb775BjU1NQ0GG0dHR6jVahQVFekNIrWsrKzq3ewMaAKaPvp+Nzt37sSMGTPw6quv6pSXlJSgc+fOOm0qKChosC0N6datGwYNGoRXXnlF73xXV1ftv2fNmoVZs2ahoqICaWlpWLlyJcaPH4+LFy/Cw8PD6G0TmRL21BBJRO2XqZWVlU75li1b2qI5eo0YMQLl5eXaSz+1Pv74Y4OWl8lk9fbvxx9/xLfffqtTFhoaips3bzb6NFXtpZm6AamuXr164ccff9QpO3z4cJOP2TfV7v3796OwsLBemy5evGjQTd23Gz9+PH766Sf07t0bQ4cOrTfdHmpqderUCaGhoYiNjUVVVRXOnj1r1DaJTBF7aogkIjAwEPfccw/mzZuHlStXwsLCAh999BF++OGHtm6aVlRUFN58801Mnz4da9aswX333Ycvv/wSBw4cAIBGLxcBmi/v1atXY+XKlRgxYgQuXLiAVatWwdPTU+fR5WnTpmH79u2YN28eLly4gFGjRqGmpgYnTpyAl5cXpk6diqCgIERGRmLNmjX47bffMH78eFhZWSErKwu2trZ47rnnAGgu2SxfvhwrVqzAiBEjcO7cObzzzjtQKBQG7/f48eORmJiIfv36YdCgQcjMzMTrr79e71JTTEwMkpOTMWHCBCxZsgQPPfQQ/vjjDxw7dgzjx4/HqFGj9K5/1apVSE1NRWBgIP7xj3+gb9++uHnzJi5fvoyUlBRs3rwZbm5u+Pvf/w4bGxs8/PDDcHFxQVFREeLj46FQKPDggw8avD9Epoqhhkgiunbtiv3792Px4sWYPn06OnXqhAkTJiA5ORk+Pj5t3TwAmt6Bw4cPIyYmBi+++CJkMhlCQkKwceNGjB07VudSjD6xsbG4ceMGtm3bhn/961/o378/Nm/ejE8//VRn3JyOHTsiJSUF8fHxSEpKQkJCAuzt7TF48GCdm5QTExPh4+ODbdu2ITExETY2Nujfv7/OuC3/7//9P5SVlSExMRFvvPEGHnroIezevRsTJkwweL83bNgACwsLxMfH4/r16/Dx8YFSqcSyZct06tnb2+Obb75BXFwctm7dipdffhn33HMPHnzwQTz99NMNrt/FxQXfffcdVq9ejddffx0FBQWwt7eHp6cnHnvsMdxzzz0AgKCgICQmJmL37t34v//7P3Tr1g3Dhg3Djh074OjoaPD+EJkqjihMRG3u1VdfxbJly5CXl8eh/4mo2dhTQ0St6p133gEA9OvXD7du3cLhw4fx1ltvYfr06Qw0RHRHGGqIqFXZ2trizTffxOXLl1FZWYmePXvipZdeqncphojIWLz8RERERJLAR7qJiIhIEhhqiIiISBIYaoiIiEgS2tWNwjU1Nfj1119hb2+vdyhzIiIiMj1CCJSXlzf5Trd2FWp+/fVXuLu7t3UziIiIqBny8/MbHfqhXYUae3t7AJqD4uDg0MatISIiIkOUlZXB3d1d+z3ekHYVamovOTk4ODDUEBERmZmmbh3hjcJEREQkCQw1REREJAkMNURERCQJ7eqeGkOo1WrcunWrrZtB1CC5XI6OHTtyWAIiojoYam5z/fp1FBQUgK/DIlNna2sLFxcXWFpatnVTiIhMBkPNn9RqNQoKCmBrawtHR0f+FUwmSQiBqqoqXL16Fbm5uejTp0+jA1EREbUnDDV/unXrFoQQcHR0hI2NTVs3h6hBNjY2sLCwwJUrV1BVVQVra+u2bhIRkUngn3h1sIeGzAF7Z4iI6mNPDREREd0RtRpITwdUKsDFBQgKAuTy1m8HQw0RERE1m1IJLFwIFBT8VebmBmzYAISHt25b2IfdwtRq4OhRIClJ81OtbusWGW/kyJGIiYkxuP7ly5chk8lw+vTpu9YmIiIyPUolMHmybqABgMJCTblS2brtYU9NC2rttNrU/T9RUVFITEw0er1KpRIWFhYG13d3d4dKpUK3bt2M3hYREZkntVrznadvFBQhAJkMiIkBJkxovUtRDDUtpDat1v3l1qbVPXtaPtioVCrtv5OTk7FixQpcuHBBW1b3Ka5bt24ZFFa6dOliVDvkcjmcnZ2NWkYqqqqqOFYMEbVL6en1e2huJwSQn6+pN3Jk67SJl59aQFNpFdCk1Za+FOXs7KydFAoFZDKZ9vPNmzfRuXNn7N69GyNHjoS1tTV27tyJa9euYdq0aXBzc4OtrS0GDhyIpKQknfXWvfzUq1cvvPrqq5g9ezbs7e3Rs2dPbN26VTu/7uWno0ePQiaT4dChQxg6dChsbW0RGBioE7gAYM2aNejevTvs7e0xd+5cLFmyBA888ECD+6tWqzFnzhx4enrCxsYGffv2xYYNG+rVe//99+Ht7Q0rKyu4uLhgwYIF2nm///47nn76aTg5OcHa2hoDBgzAF198AQCIi4urt/2EhAT06tVL+3nmzJmYOHEi4uPj4erqivvvvx8AsHPnTgwdOhT29vZwdnbGk08+ieLiYp11nT17FuPGjYODgwPs7e0RFBSEX375BWlpabCwsEBRUZFO/cWLF2P48OENHg8iorZ029/VLVKvJTDUtABj0mpre+mll/CPf/wD2dnZGDNmDG7evAlfX1988cUX+Omnn/D0008jMjISJ06caHQ969atw9ChQ5GVlYX58+fj2Wefxfnz5xtdJjY2FuvWrcN3332Hjh07Yvbs2dp5H330EV555RW89tpryMzMRM+ePbFp06ZG11dTUwM3Nzfs3r0b586dw4oVK/DPf/4Tu3fv1tbZtGkToqOj8fTTT+PMmTP4/PPPcd9992mXDw0NRUZGBnbu3Ilz585h7dq1kBvZL3ro0CFkZ2cjNTVVG4iqqqqwevVq/PDDD9i3bx9yc3Mxc+ZM7TKFhYUYPnw4rK2tcfjwYWRmZmL27Nmorq7G8OHDce+99+LDDz/U1q+ursbOnTsxa9Yso9pGRNRaXFxatl6LEM3w7rvvil69egkrKyvh4+Mj0tLSGqybnp4uAgMDRZcuXYS1tbXo27evWL9+fb16e/bsEV5eXsLS0lJ4eXkJpVJ5R9vVp7S0VAAQpaWl9eb98ccf4ty5c+KPP/4wap1CCLFrlxCa6NL4tGuX0as22Pbt24VCodB+zs3NFQBEQkJCk8uOHTtWLF68WPt5xIgRYuHChdrPHh4eYvr06drPNTU1onv37mLTpk0628rKyhJCCHHkyBEBQHz99dfaZfbv3y8AaI+vn5+fiI6O1mnHww8/LAYPHmzoLgshhJg/f76YNGmS9rOrq6uIjY3VW/fAgQOiQ4cO4sKFC3rnr1y5st7233zzTeHh4aH9HBUVJZycnERlZWWj7Tp58qQAIMrLy4UQQixdulR4enqKqqoqvfVfe+014eXlpf28b98+YWdnJ65fv663/p2cr0RELaG6Wgg3NyFkMv3feTKZEO7umnp3qrHv79sZ3VOTnJyMmJgYxMbGIisrC0FBQQgNDUVeXp7e+p06dcKCBQuQlpaG7OxsLFu2DMuWLdO5fPHtt98iIiICkZGR+OGHHxAZGYkpU6bo9B4Yu93WZJJp9U9Dhw7V+axWq/HKK69g0KBB6Nq1K+zs7HDw4MEmj+OgQYO0/669zFX38kpjy7j8ufO1y1y4cAEPPfSQTv26n/XZvHkzhg4dCkdHR9jZ2eG9997Ttr24uBi//vorHn30Ub3Lnj59Gm5ubtpLRs01cODAevfRZGVlYcKECfDw8IC9vT1G/nkBubZtp0+fRlBQUIP3NM2cORM///wzjh8/DkBzCW3KlCno1KnTHbWViOhukcs1D8IAmpuCb1f7OSGhdcerMTrUrF+/HnPmzMHcuXPh5eWFhIQEuLu7N3jpYMiQIZg2bRq8vb3Rq1cvTJ8+HWPGjEH6bddiEhISEBwcjKVLl6Jfv35YunQpHn30USQkJDR7u60pKEjzlFNDDyPJZIC7u6Zea6v7pbhu3Tq8+eabePHFF3H48GGcPn0aY8aMQVVVVaPrqftlLJPJUFNTY/AytU9q3b5M3ae3RBMvEt29ezeef/55zJ49GwcPHsTp06cxa9Ysbduber1FU/M7dOhQrw363the95hWVFQgJCQEdnZ22LlzJ06dOoVPP/0UAAxuW/fu3REWFobt27ejuLgYKSkpOpfriIhMUXi45kGYHj10y93c7s4DMk0xKtRUVVUhMzMTISEhOuUhISHIyMgwaB1ZWVnIyMjAiBEjtGXffvttvXWOGTNGu87mbreyshJlZWU6091gimm1Ienp6ZgwYQKmT5+OwYMH495770VOTk6rt6Nv3744efKkTtl3333X6DLp6ekIDAzE/PnzMWTIENx333345ZdftPPt7e3Rq1cvHDp0SO/ygwYNQkFBAS5evKh3vqOjI4qKinSCjSFj75w/fx4lJSVYu3YtgoKC0K9fv3q9WIMGDUJ6errekFRr7ty5+Pjjj7Flyxb07t0bDz/8cJPbJiJqa+HhwOXLwJEjwK5dmp+5ua0faAAjQ01JSQnUajWcnJx0yp2cnOo9uVGXm5sbrKysMHToUERHR2Pu3LnaeUVFRY2us7nbjY+Ph0Kh0E7u7u4G7WdzmFpabch9992H1NRUZGRkIDs7G88880yTv7u74bnnnsO2bdvwwQcfICcnB2vWrMGPP/7Y6Ng79913H7777jscOHAAFy9exPLly3Hq1CmdOnFxcVi3bh3eeust5OTk4Pvvv8fbb78NABgxYgSGDx+OSZMmITU1Fbm5ufjyyy/x1VdfAdA89XX16lX861//wi+//IJ3330XX375ZZP70rNnT1haWuLtt9/GpUuX8Pnnn2P16tU6dRYsWICysjJMnToV3333HXJycvDhhx/qPBE2ZswYKBQKrFmzhjcIE5FZkcs1j21Pm6b52VZ/xDfr6Sd9lw2aGgguPT0d3333HTZv3oyEhIR6jxEbsk5jt7t06VKUlpZqp/z8/EbbeKdMKa02ZPny5fDx8cGYMWMwcuRIODs7Y+LEia3ejqeeegpLly7FCy+8AB8fH+3TQo29cXrevHkIDw9HREQE/Pz8cO3aNcyfP1+nTlRUFBISErBx40Z4e3tj/PjxOj1Re/fuxYMPPohp06ahf//+ePHFF6H+81l7Ly8vbNy4Ee+++y4GDx6MkydP4oUXXmhyXxwdHZGYmIhPPvkE/fv3x9q1a/HGG2/o1OnatSsOHz6M69evY8SIEfD19cV7772nc4muQ4cOmDlzJtRqNWbMmGHQcSQiotsYc/dxZWWlkMvl9Z5M+sc//iGGDx9u8HpWr14t7r//fu1nd3f3ek9ErV+/XvTs2bNFt3u3nn6iljF69Gidp6zao7lz54qwsLAm6/F8JaL25K48/WRpaQlfX1+kpqbqlKempiIwMNCYIIXKykrt54CAgHrrPHjwoHadLbVdMh03btzA+vXrcfbsWZw/fx4rV67E119/jaioqLZuWpsoLS3F119/jY8++gjPPfdcWzeHiO4iKbwj0GQZm5Y+/vhjYWFhIbZt2ybOnTsnYmJiRKdOncTly5eFEEIsWbJEREZGauu/88474vPPPxcXL14UFy9eFO+//75wcHDQGUvkv//9r5DL5WLt2rUiOztbrF27VnTs2FEcP37c4O0agj01puPGjRvi0UcfFffcc4+wtbUVQ4YMEXv37m3rZrWZESNGCBsbGxETE2NQfZ6vROZp717N2C63j+fi5qYpp4YZ2lPT7MH3PDw8hKWlpfDx8RHHjh3TzouKihIjRozQfn7rrbeEt7e3sLW1FQ4ODmLIkCFi48aNQq1W66zzk08+EX379hUWFhaiX79+er/gGtuuIRhqSCp4vhKZn7179Q9UJ5NpJgabhhkaamRCNDE4iISUlZVBoVCgtLQUDg4OOvNu3ryJ3NxceHp6NnqzKpEp4PlKZF7UaqBXr4ZfqSOTaZ6Wzc01jeE/TE1j39+347uf6mhHGY/MGM9TIvNiyu8IlBKGmj/VvtSwqZF1iUzBjRs3ANQf6ZmITJMpvtFaijq2dQNMRceOHWFra4urV6/CwsICHTow75HpEULgxo0bKC4uRufOnY1+wzgRtQ1TfkeglDDU/Ekmk8HFxQW5ubm4cuVKWzeHqFGdO3eGs7NzWzeDiAxU+47AwkLNpaa6au+paYt3BEoJQ81tLC0t0adPH16CIpNmYWHBHhoiM1P7jsDJkzUB5vZgY2rvCDRnDDV1dOjQgU+TEBFRi6t9R+DChbo3Dbu5aQKNKb1Sx1wx1BAREbWS8HBgwgTNU04qleYemqAg9tC0FIYaIiKiVlT7RmtqeQw1REREEqVWt69eIYYaIiJq96T45a9U6r9/Z8MG6d6/w8FYiIioXVMqNa8wGDUKePJJzc9evTTl5kqp1DxpVXcU48JCTbk571tjGGqIiKjdkuKXv1qt6aHRNx5ObVlMjKae1DDUEBFRuyTVL//2/J4phhoiIjJZajVw9CiQlKT52ZIBQ6pf/u35PVO8UZiIiEzS3b7RVapf/u35PVPsqSEiIpPTGve6SPXLv/Y9U7WvX6hLJgPc3aX5nimGGiIiMimtda+LVL/8a98zBdTfN6m/Z4qhhoiITEpr3esi5S//2vdM9eihW+7mpimX6jg1vKeGiIiMcrcHqmvNe12k/JLJ9vieKYYaIiIyWGuMUtva97pI+cu/vb1nSiaEvquW0lRWVgaFQoHS0lI4ODi0dXOIiMxK7c27db81ai/VtNRlDbVaM6JvYaH++2pkMk2Qys2VRvCgphn6/c17aoiIqEmtOVCdlO91obuLoYaIiJrU2gPVtdcbXenO8J4aIiJqUlsMVCfle13o7mCoISKSiLv5VFJbDVTX3m50pTvDy09ERBKgVGpurh01CnjySc3PXr1a7i3TUh2ojqSFoYaIyMy1xisFePMumQOGGiIiM9aaTyXx5l0ydbynhojIjBnzVFJL3JvCm3fJlDHUEBGZsbZ4Kok375Kp4uUnIiIz1lZPJRGZIoYaIiIzxqeSiP7CUENEZMb4VBLRXxhqiIjMHJ9KItLgjcJERBLAp5KIGGqIiCSDTyVRe8fLT0RERCQJDDVEREQkCQw1REREJAnNCjUbN26Ep6cnrK2t4evri/T09AbrKpVKBAcHw9HREQ4ODggICMCBAwd06ty6dQurVq1C7969YW1tjcGDB+Orr77SqRMXFweZTKYzOTs7N6f5REREJEFGh5rk5GTExMQgNjYWWVlZCAoKQmhoKPLy8vTWT0tLQ3BwMFJSUpCZmYlRo0YhLCwMWVlZ2jrLli3Dli1b8Pbbb+PcuXOYN28ennjiCZ06AODt7Q2VSqWdzpw5Y2zziYiISKJkQuh7t2vD/Pz84OPjg02bNmnLvLy8MHHiRMTHxxu0Dm9vb0RERGDFihUAAFdXV8TGxiI6OlpbZ+LEibCzs8POnTsBaHpq9u3bh9OnTxvc1srKSlRWVmo/l5WVwd3dHaWlpXBwcDB4PURERNR2ysrKoFAomvz+NqqnpqqqCpmZmQgJCdEpDwkJQUZGhkHrqKmpQXl5Obp06aItq6yshLW1tU49GxsbfPPNNzplOTk5cHV1haenJ6ZOnYpLly41uq34+HgoFArt5O7ublAbiYiIyPwYFWpKSkqgVqvh5OSkU+7k5ISioiKD1rFu3TpUVFRgypQp2rIxY8Zg/fr1yMnJQU1NDVJTU/HZZ59BddtrZf38/LBjxw4cOHAA7733HoqKihAYGIhr1641uK2lS5eitLRUO+Xn5xuzu0RERGRGmnWjsKzOC0aEEPXK9ElKSkJcXBySk5PRvXt3bfmGDRvQp08f9OvXD5aWlliwYAFmzZoF+W1DYYaGhmLSpEkYOHAgRo8ejf379wMAPvjggwa3Z2VlBQcHB52JiIiIpMmoUNOtWzfI5fJ6vTLFxcX1em/qSk5Oxpw5c7B7926MHj1aZ56joyP27duHiooKXLlyBefPn4ednR08PT0bXF+nTp0wcOBA5OTkGLMLREREJFFGhRpLS0v4+voiNTVVpzw1NRWBgYENLpeUlISZM2di165dGDduXIP1rK2t0aNHD1RXV2Pv3r2YMGFCg3UrKyuRnZ0NFxcXY3aBiIiIJMrodz8tWrQIkZGRGDp0KAICArB161bk5eVh3rx5ADT3sRQWFmLHjh0ANIFmxowZ2LBhA/z9/bW9PDY2NlAoFACAEydOoLCwEA888AAKCwsRFxeHmpoavPjii9rtvvDCCwgLC0PPnj1RXFyMNWvWoKysDFFRUXd8EIiIiMj8GR1qIiIicO3aNaxatQoqlQoDBgxASkoKPDw8AAAqlUpnzJotW7aguroa0dHROo9sR0VFITExEQBw8+ZNLFu2DJcuXYKdnR3Gjh2LDz/8EJ07d9bWLygowLRp01BSUgJHR0f4+/vj+PHj2u0SERFR+2b0ODXmzNDn3ImIiMh03JVxaoiIiIhMFUMNERERSQJDDREREUmC0TcKExFJgVoNpKcDKhXg4gIEBQG3jfdJRGaIoYaI2h2lEli4ECgo+KvMzQ3YsAEID2+7dhHRneHlJyJqV5RKYPJk3UADAIWFmnKlsm3aRUR3jqGGiEyGWg0cPQokJWl+qtUtv/6FCwF9A1nUlsXEtPx2iah1MNQQkUlQKoFevYBRo4Ann9T87NWrZXtO0tPr99DcTgggP19Tr6Xc7aBGRH9hqCGiNtdal4RUqpat15TWCGpE9BeGGiJqU615ScjQ99+2xHtyee8OUetjqCGiNtWal4SCgjRPOclk+ufLZIC7u6beneC9O0Rtg6GGiNpUa14Skss1j20D9YNN7eeEhDsfr6Yt7t0hIoYaImpjrXlJCNCMQ7NnD9Cjh265m5umvCXGqWnte3eISIOD7xFRm6q9JFRYqP9yjUymmX+nl4RuFx4OTJhw90YUbu2gRkQaDDVE1KZqLwlNnqwJMLcHm5a8JKRvuyNHtuw6a7VFUCMiXn4iIhPQGpeEWlNr3btDRLpkQuj7O0KaysrKoFAoUFpaCgcHh7ZuDhHVIbWXTOp7x5S7uybQmFtQI2pLhn5/M9QQEd1FUgtqRG3B0O9v3lNDRHQX3c17d4hIF++pISIiIklgqCEiIiJJYKghIiIiSWCoISIiIklgqCEiIiJJYKghIiIiSWCoISIiIklgqCEiIiJJYKghIiIiSeCIwkRmisPvExHpYqghMkP6XpTo5qZ5MzRflEhE7RUvPxGZGaUSmDxZN9AAQGGhplypbJt2ERG1NYYaIjOiVmt6aISoP6+2LCZGU4+IqL1hqCEyI+np9XtobicEkJ+vqUdE1N4w1BCZEZWqZesREUkJQw2RGXFxadl6RERSwlBDZEaCgjRPOclk+ufLZIC7u6YeEVF7w1BDZEbkcs1j20D9YFP7OSGB49UQUfvEUENkZsLDgT17gB49dMvd3DTlHKeGiNqrZoWajRs3wtPTE9bW1vD19UV6I49aKJVKBAcHw9HREQ4ODggICMCBAwd06ty6dQurVq1C7969YW1tjcGDB+Orr766o+0SSVl4OHD5MnDkCLBrl+Znbi4DDRG1b0aHmuTkZMTExCA2NhZZWVkICgpCaGgo8vLy9NZPS0tDcHAwUlJSkJmZiVGjRiEsLAxZWVnaOsuWLcOWLVvw9ttv49y5c5g3bx6eeOIJnTrGbpdI6uRyYORIYNo0zU9eciKi9k4mhL5hvBrm5+cHHx8fbNq0SVvm5eWFiRMnIj4+3qB1eHt7IyIiAitWrAAAuLq6IjY2FtHR0do6EydOhJ2dHXbu3Nli2y0rK4NCoUBpaSkcHBwMWoaIiIjalqHf30b11FRVVSEzMxMhISE65SEhIcjIyDBoHTU1NSgvL0eXLl20ZZWVlbC2ttapZ2Njg2+++eaOtltZWYmysjKdiYiIiKTJqFBTUlICtVoNJycnnXInJycUFRUZtI5169ahoqICU6ZM0ZaNGTMG69evR05ODmpqapCamorPPvsMqj9HEGvuduPj46FQKLSTu7u7obtKREREZqZZNwrL6jxLKoSoV6ZPUlIS4uLikJycjO7du2vLN2zYgD59+qBfv36wtLTEggULMGvWLMjr3CRg7HaXLl2K0tJS7ZSfn2/I7hEREZEZMirUdOvWDXK5vF7vSHFxcb1elLqSk5MxZ84c7N69G6NHj9aZ5+joiH379qGiogJXrlzB+fPnYWdnB09PzzvarpWVFRwcHHQmIiIikiajQo2lpSV8fX2RmpqqU56amorAwMAGl0tKSsLMmTOxa9cujBs3rsF61tbW6NGjB6qrq7F3715MmDDhjrZLRERE7UdHYxdYtGgRIiMjMXToUAQEBGDr1q3Iy8vDvHnzAGgu+RQWFmLHjh0ANIFmxowZ2LBhA/z9/bW9LTY2NlAoFACAEydOoLCwEA888AAKCwsRFxeHmpoavPjiiwZvl4iIiNo3o0NNREQErl27hlWrVkGlUmHAgAFISUmBh4cHAEClUumMHbNlyxZUV1cjOjpa55HtqKgoJCYmAgBu3ryJZcuW4dKlS7Czs8PYsWPx4YcfonPnzgZvl4iIiNo3o8epMWccp4aIiMj83JVxaoiIiIhMFUMNERERSQJDDREREUkCQw0RERFJAkMNERERSQJDDREREUkCQw0RERFJAkMNERERSQJDDREREUkCQw0RERFJAkMNERERSQJDDREREUkCQw0RERFJAkMNERERSQJDDREREUkCQw0RERFJAkMNERERSQJDDREREUkCQw0RERFJAkMNERERSULHtm4AkdSo1UB6OqBSAS4uQFAQIJe3dauIiKSPoYaoBSmVwMKFQEHBX2VubsCGDUB4eNu1i4ioPeDlJ6IWolQCkyfrBhoAKCzUlCuVbdMuIqL2gqGGqAWo1ZoeGiHqz6sti4nR1CMioruDoYaoBaSn1++huZ0QQH6+ph4REd0dDDVELUClatl6RERkPIYaohbg4tKy9YiIyHgMNUQtIChI85STTKZ/vkwGuLtr6hER0d3BUEPUAuRyzWPbQP1gU/s5IcF8x6tRq4GjR4GkJM1P3vBMRKaIoYaohYSHA3v2AD166Ja7uWnKzXWcGqUS6NULGDUKePJJzc9evfiIOhGZHpkQ+h5ClaaysjIoFAqUlpbCwcGhrZtDrag1R/mV0ojCtWPv1P2/RG3vkzmHNSIyH4Z+fzPUkORxlN/mUas1PTINPaouk2mOY26u+YY2IjIPhn5/8/ITSRpH+W0+jr1DROaGoYYki6P83hmOvUNE5oahhiSLPQ13hmPvEJG5YaghyWJPw53h2DtEZG4Yakiy2NNwZ6Q+9g4RSQ9DDUkWexrunFTH3iEiaWpWqNm4cSM8PT1hbW0NX19fpDdyU4JSqURwcDAcHR3h4OCAgIAAHDhwoF69hIQE9O3bFzY2NnB3d8fzzz+PmzdvaufHxcVBJpPpTM7Ozs1pPrUT7GloGeHhwOXLwJEjwK5dmp+5uQw0RGR6jA41ycnJiImJQWxsLLKyshAUFITQ0FDk5eXprZ+Wlobg4GCkpKQgMzMTo0aNQlhYGLKysrR1PvroIyxZsgQrV65EdnY2tm3bhuTkZCxdulRnXd7e3lCpVNrpzJkzxjaf2hn2NLQMuRwYORKYNk3zk0GQiEyR0YPv+fn5wcfHB5s2bdKWeXl5YeLEiYiPjzdoHd7e3oiIiMCKFSsAAAsWLEB2djYOHTqkrbN48WKcPHlS2wsUFxeHffv24fTp08Y0VwcH32u/pDTKLxFRe3NXBt+rqqpCZmYmQkJCdMpDQkKQkZFh0DpqampQXl6OLl26aMuGDRuGzMxMnDx5EgBw6dIlpKSkYNy4cTrL5uTkwNXVFZ6enpg6dSouXbrU6LYqKytRVlamM1H7xJ4GIiLp62hM5ZKSEqjVajg5OemUOzk5oaioyKB1rFu3DhUVFZgyZYq2bOrUqbh69SqGDRsGIQSqq6vx7LPPYsmSJdo6fn5+2LFjB+6//3789ttvWLNmDQIDA3H27Fl07dpV77bi4+Px8ssvG7OLREREZKaadaOwrM5dl0KIemX6JCUlIS4uDsnJyejevbu2/OjRo3jllVewceNGfP/991Aqlfjiiy+wevVqbZ3Q0FBMmjQJAwcOxOjRo7F//34AwAcffNDg9pYuXYrS0lLtlJ+fb+yuEhERkZkwqqemW7dukMvl9XpliouL6/Xe1JWcnIw5c+bgk08+wejRo3XmLV++HJGRkZg7dy4AYODAgaioqMDTTz+N2NhYdOhQP3t16tQJAwcORE5OToPbtLKygpWVlaG7R0RERGbMqJ4aS0tL+Pr6IjU1Vac8NTUVgYGBDS6XlJSEmTNnYteuXfXukwGAGzdu1AsucrkcQgg0dB9zZWUlsrOz4cKR04iIiAhG9tQAwKJFixAZGYmhQ4ciICAAW7duRV5eHubNmwdAc8mnsLAQO3bsAKAJNDNmzMCGDRvg7++v7eWxsbGBQqEAAISFhWH9+vUYMmQI/Pz88PPPP2P58uV4/PHHIf/zjs4XXngBYWFh6NmzJ4qLi7FmzRqUlZUhKiqqRQ4EtQ0+lURERC3F6FATERGBa9euYdWqVVCpVBgwYABSUlLg4eEBAFCpVDpj1mzZsgXV1dWIjo5GdHS0tjwqKgqJiYkAgGXLlkEmk2HZsmUoLCyEo6MjwsLC8Morr2jrFxQUYNq0aSgpKYGjoyP8/f1x/Phx7XbJ/CiVmrdo3/7SSTc3zYB5HD+GiIiMZfQ4NeaM49SYDqUSmDxZ86bs29Xeb86B8YiIqNZdGaeGqCWo1ZoeGn1xurYsJkZTj4iIyFAMNdTq0tN1LznVJQSQn6+pR0REZCiGGmp1KlXL1iMiIgIYaqgNGPoUPp/WJyIiYzDUUKsLCtI85dTQINQyGeDurqlHRERkKIYaanVyueaxbaB+sKn9nJDA8WqIiMg4DDXUJsLDNY9t9+ihW+7mxse5iYioeYwefI+opYSHAxMmcERhIiJqGQw11KbkcmDkyLZuBRERSQEvPxEREZEkMNQQERGRJDDUEBERkSQw1BAREZEkMNQQERGRJDDUEBERkSQw1BAREZEkMNQQERGRJDDUEBERkSQw1BAREZEkMNQQERGRJDDUEBERkSQw1BAREZEkMNQQERGRJDDUEBERkSQw1BAREZEkMNQQERGRJDDUEBERkSQw1BAREZEkMNQQERGRJDDUEBERkSR0bOsGkOlRq4H0dEClAlxcgKAgQC5v61YRERE1jqGGdCiVwMKFQEHBX2VubsCGDUB4eNu1i4iIqCm8/ERaSiUwebJuoAGAwkJNuVLZNu0iIiIyBEMNAdBcclq4EBCi/rzaspgYTT0iIiJTxFBDADT30NTtobmdEEB+vqYeERGRKWKoIQCam4Jbsh4REVFrY6ghAJqnnFqyHhERUWtjqCEAmse23dwAmUz/fJkMcHfX1CMiIjJFDDUEQDMOzYYNmn/XDTa1nxMSOF4NERGZrmaFmo0bN8LT0xPW1tbw9fVFeiN3jyqVSgQHB8PR0REODg4ICAjAgQMH6tVLSEhA3759YWNjA3d3dzz//PO4efNms7dLxgsPB/bsAXr00C13c9OUc5waIiIyZUaHmuTkZMTExCA2NhZZWVkICgpCaGgo8vLy9NZPS0tDcHAwUlJSkJmZiVGjRiEsLAxZWVnaOh999BGWLFmClStXIjs7G9u2bUNycjKWLl3a7O1S84SHA5cvA0eOALt2aX7m5jLQEBGR6ZMJoW9kkob5+fnBx8cHmzZt0pZ5eXlh4sSJiI+PN2gd3t7eiIiIwIoVKwAACxYsQHZ2Ng4dOqSts3jxYpw8eVLbG9MS2y0rK4NCoUBpaSkcHBwMWoaIiIjalqHf30b11FRVVSEzMxMhISE65SEhIcjIyDBoHTU1NSgvL0eXLl20ZcOGDUNmZiZOnjwJALh06RJSUlIwbty4O9puZWUlysrKdCYiIiKSJqPe/VRSUgK1Wg0nJyedcicnJxQVFRm0jnXr1qGiogJTpkzRlk2dOhVXr17FsGHDIIRAdXU1nn32WSxZsuSOthsfH4+XX37Z0N0jIiIiM9asG4VldR6PEULUK9MnKSkJcXFxSE5ORvfu3bXlR48exSuvvIKNGzfi+++/h1KpxBdffIHVq1ff0XaXLl2K0tJS7ZSfn2/I7hEREZEZMqqnplu3bpDL5fV6R4qLi+v1otSVnJyMOXPm4JNPPsHo0aN15i1fvhyRkZGYO3cuAGDgwIGoqKjA008/jdjY2GZv18rKClZWVsbsIhEREZkpo3pqLC0t4evri9TUVJ3y1NRUBAYGNrhcUlISZs6ciV27dmnvk7ndjRs30KGDblPkcjmEEBBCNHu7RERE1H4Y1VMDAIsWLUJkZCSGDh2KgIAAbN26FXl5eZg3bx4AzSWfwsJC7NixA4Am0MyYMQMbNmyAv7+/trfFxsYGCoUCABAWFob169djyJAh8PPzw88//4zly5fj8ccfh/zP0d6a2i4RERG1b0aHmoiICFy7dg2rVq2CSqXCgAEDkJKSAg8PDwCASqXSGTtmy5YtqK6uRnR0NKKjo7XlUVFRSExMBAAsW7YMMpkMy5YtQ2FhIRwdHREWFoZXXnnF4O0SERFR+2b0ODXmjOPUEBERmZ+7Mk4NERERkaliqCEiIiJJYKghIiIiSWCoISIiIklgqCEiIiJJYKghIiIiSWCoISIiIklgqCEiIiJJYKghIiIiSWCoISIiIklgqCEiIiJJYKghIiIiSWCoISIiIklgqCEiIiJJYKghIiIiSWCoISIiIklgqCEiIiJJYKghIiIiSWCoISIiIklgqCEiIiJJ6NjWDSDDqdVAejqgUgEuLkBQECCXt3WriIiITANDjZlQKoGFC4GCgr/K3NyADRuA8PC2axcREZGp4OUnM6BUApMn6wYaACgs1JQrlW3TLiIiIlPCUGPi1GpND40Q9efVlsXEaOoRERG1Zww1Ji49vX4Pze2EAPLzNfWIiIjaM4YaE6dStWw9IiIiqWKoMXEuLi1bj4iISKoYakxcUJDmKSeZTP98mQxwd9fUIyIias8YakycXK55bBuoH2xqPyckcLwaIiIihhozEB4O7NkD9OihW+7mpinnODVEREQcfM9shIcDEyZwRGEiIqKGMNSYEbkcGDmyrVtBRERkmnj5iYiIiCSBoYaIiIgkgaGGiIiIJIGhhoiIiCSBoYaIiIgkgaGGiIiIJKFZoWbjxo3w9PSEtbU1fH19kd7IK6KVSiWCg4Ph6OgIBwcHBAQE4MCBAzp1Ro4cCZlMVm8aN26ctk5cXFy9+c7Ozs1pPhEREUmQ0aEmOTkZMTExiI2NRVZWFoKCghAaGoq8vDy99dPS0hAcHIyUlBRkZmZi1KhRCAsLQ1ZWlraOUqmESqXSTj/99BPkcjn+9re/6azL29tbp96ZM2eMbT4RERFJlEwIIYxZwM/PDz4+Pti0aZO2zMvLCxMnTkR8fLxB6/D29kZERARWrFihd35CQgJWrFgBlUqFTp06AdD01Ozbtw+nT582prk6ysrKoFAoUFpaCgcHh2avh4iIiFqPod/fRvXUVFVVITMzEyEhITrlISEhyMjIMGgdNTU1KC8vR5cuXRqss23bNkydOlUbaGrl5OTA1dUVnp6emDp1Ki5dutTotiorK1FWVqYzERERkTQZFWpKSkqgVqvh5OSkU+7k5ISioiKD1rFu3TpUVFRgypQpeuefPHkSP/30E+bOnatT7ufnhx07duDAgQN47733UFRUhMDAQFy7dq3BbcXHx0OhUGgnd3d3g9pIRERE5qdZNwrLZDKdz0KIemX6JCUlIS4uDsnJyejevbveOtu2bcOAAQPw0EMP6ZSHhoZi0qRJGDhwIEaPHo39+/cDAD744IMGt7d06VKUlpZqp/z8/CbbSERERObJqBdaduvWDXK5vF6vTHFxcb3em7qSk5MxZ84cfPLJJxg9erTeOjdu3MDHH3+MVatWNdmWTp06YeDAgcjJyWmwjpWVFaysrJpcFxEREZk/o3pqLC0t4evri9TUVJ3y1NRUBAYGNrhcUlISZs6ciV27duk8pl3X7t27UVlZienTpzfZlsrKSmRnZ8PFxcXwHSAiIiLJMqqnBgAWLVqEyMhIDB06FAEBAdi6dSvy8vIwb948AJpLPoWFhdixYwcATaCZMWMGNmzYAH9/f20vj42NDRQKhc66t23bhokTJ6Jr1671tvvCCy8gLCwMPXv2RHFxMdasWYOysjJERUUZvdNEREQkPUaHmoiICFy7dg2rVq2CSqXCgAEDkJKSAg8PDwCASqXSGbNmy5YtqK6uRnR0NKKjo7XlUVFRSExM1H6+ePEivvnmGxw8eFDvdgsKCjBt2jSUlJTA0dER/v7+OH78uHa7RERE1L4ZPU6NOeM4NURERObnroxTQ0RERGSqGGqIiIhIEhhqiIiISBIYaoiIiEgSGGqIiIhIEhhqiIiISBIYaoiIiEgSGGqIiIhIEhhqiIiISBIYaoiIiEgSGGqIiIhIEhhqiIiISBIYaoiIiEgSGGqIiIhIEhhqiIiISBIYaoiIiEgSGGqIiIhIEhhqiIiISBIYaoiIiEgSGGqIiIhIEhhqiIiISBIYaoiIiEgSGGqIiIhIEhhqiIiISBIYaoiIiEgSGGqIiIhIEhhqiIiISBIYaoiIiEgSGGqIiIhIEhhqiIiISBIYaoiIiEgSGGqIiIhIEhhqiIiISBIYaoiIiEgSGGqIiIhIEhhqiIiISBIYaoiIiEgSGGqIiIhIEhhqiIiISBKaFWo2btwIT09PWFtbw9fXF+np6Q3WVSqVCA4OhqOjIxwcHBAQEIADBw7o1Bk5ciRkMlm9ady4cc3eLhEREbUvRoea5ORkxMTEIDY2FllZWQgKCkJoaCjy8vL01k9LS0NwcDBSUlKQmZmJUaNGISwsDFlZWdo6SqUSKpVKO/3000+Qy+X429/+1uztEhERUfsiE0IIYxbw8/ODj48PNm3apC3z8vLCxIkTER8fb9A6vL29ERERgRUrVuidn5CQgBUrVkClUqFTp07N3m5lZSUqKyu1n8vKyuDu7o7S0lI4ODgY1FYiIiJqW2VlZVAoFE1+fxvVU1NVVYXMzEyEhITolIeEhCAjI8OgddTU1KC8vBxdunRpsM62bdswdepUbaBp7nbj4+OhUCi0k7u7u0FtJCIiIvNjVKgpKSmBWq2Gk5OTTrmTkxOKiooMWse6detQUVGBKVOm6J1/8uRJ/PTTT5g7d+4db3fp0qUoLS3VTvn5+Qa1kYiIiMxPx+YsJJPJdD4LIeqV6ZOUlIS4uDh89tln6N69u94627Ztw4ABA/DQQw/d8XatrKxgZWXVZLuIiIjI/BnVU9OtWzfI5fJ6vSPFxcX1elHqSk5Oxpw5c7B7926MHj1ab50bN27g448/1umludPtEhERUftgVKixtLSEr68vUlNTdcpTU1MRGBjY4HJJSUmYOXMmdu3aVe8x7dvt3r0blZWVmD59eotsl4iIiNoPoy8/LVq0CJGRkRg6dCgCAgKwdetW5OXlYd68eQA097EUFhZix44dADSBZsaMGdiwYQP8/f21vS02NjZQKBQ66962bRsmTpyIrl27Gr1dIiIiat+MDjURERG4du0aVq1aBZVKhQEDBiAlJQUeHh4AAJVKpTN2zJYtW1BdXY3o6GhER0dry6OiopCYmKj9fPHiRXzzzTc4ePBgs7ZLRERE7ZvR49SYM0OfcyciIiLTcVfGqSEiIiIyVQw1REREJAkMNURERCQJDDVEREQkCQw1REREJAkMNURERCQJDDVEREQkCQw1REREJAkMNURERCQJDDVEREQkCQw1REREJAkMNURERCQJDDVEREQkCQw1REREJAkMNURERCQJDDVEREQkCQw1REREJAkMNURERCQJDDVEREQkCQw1REREJAkMNURERCQJHdu6AeZOrQbS0wGVCnBxAYKCALm8rVtFRETU/jDU3AGlEli4ECgo+KvMzQ3YsAEID2+7dhEREbVHvPzUTEolMHmybqABgMJCTblS2TbtIiIiaq8YappBrdb00AhRf15tWUyMph4RERG1DoaaZkhPr99DczshgPx8TT0iIiJqHQw1zaBStWw9IiIiunMMNc3g4tKy9YiIiOjOMdQ0Q1CQ5iknmUz/fJkMcHfX1CMiIqLWwVDTDHK55rFtoH6wqf2ckMDxaoiIiFoTQ00zhYcDe/YAPXrolru5aco5Tg0REVHr4uB7dyA8HJgwgSMKExERmQKGmjsklwMjR7Z1K4iIiIiXn4iIiEgSGGqIiIhIEhhqiIiISBIYaoiIiEgSGGqIiIhIEpoVajZu3AhPT09YW1vD19cX6Y28uVGpVCI4OBiOjo5wcHBAQEAADhw4UK/e77//jujoaLi4uMDa2hpeXl5ISUnRzo+Li4NMJtOZnJ2dm9N8IiIikiCjQ01ycjJiYmIQGxuLrKwsBAUFITQ0FHl5eXrrp6WlITg4GCkpKcjMzMSoUaMQFhaGrKwsbZ2qqioEBwfj8uXL2LNnDy5cuID33nsPPeqMbOft7Q2VSqWdzpw5Y2zziYiISKJkQghhzAJ+fn7w8fHBpk2btGVeXl6YOHEi4uPjDVqHt7c3IiIisGLFCgDA5s2b8frrr+P8+fOwsLDQu0xcXBz27duH06dPG9NcHWVlZVAoFCgtLYWDg0Oz10NEREStx9Dvb6N6aqqqqpCZmYmQkBCd8pCQEGRkZBi0jpqaGpSXl6NLly7ass8//xwBAQGIjo6Gk5MTBgwYgFdffRVqtVpn2ZycHLi6usLT0xNTp07FpUuXGt1WZWUlysrKdCYiIiKSJqNGFC4pKYFarYaTk5NOuZOTE4qKigxax7p161BRUYEpU6Zoyy5duoTDhw/jqaeeQkpKCnJychAdHY3q6mptb46fnx927NiB+++/H7/99hvWrFmDwMBAnD17Fl27dtW7rfj4eLz88sv1yhluiIiIzEft93aTF5eEEQoLCwUAkZGRoVO+Zs0a0bdv3yaX37Vrl7C1tRWpqak65X369BHu7u6iurpaW7Zu3Trh7Ozc4LquX78unJycxLp16xqsc/PmTVFaWqqdzp07JwBw4sSJEydOnMxwys/PbzRnGNVT061bN8jl8nq9MsXFxfV6b+pKTk7GnDlz8Mknn2D06NE681xcXGBhYQH5bW+C9PLyQlFREaqqqmBpaVlvfZ06dcLAgQORk5PT4DatrKxgZWWl/WxnZ4f8/HzY29tDJpM12l4pKSsrg7u7O/Lz89v1vUQ8Dn/hsdDgcdDgcdDgcfiLqR0LIQTKy8vh6uraaD2jQo2lpSV8fX2RmpqKJ554QluempqKCRMmNLhcUlISZs+ejaSkJIwbN67e/Icffhi7du1CTU0NOnTQ3OZz8eJFuLi46A00gOZ+mezsbAQFBRnc/g4dOsDNzc3g+lLj4OBgEidnW+Nx+AuPhQaPgwaPgwaPw19M6VgoFIom6xj9SPeiRYvw73//G++//z6ys7Px/PPPIy8vD/PmzQMALF26FDNmzNDWT0pKwowZM7Bu3Tr4+/ujqKgIRUVFKC0t1dZ59tlnce3aNSxcuBAXL17E/v378eqrryI6Olpb54UXXsCxY8eQm5uLEydOYPLkySgrK0NUVJSxu0BEREQSZFRPDQBERETg2rVrWLVqFVQqFQYMGICUlBR4eHgAAFQqlc6YNVu2bEF1dTWio6N1QkpUVBQSExMBAO7u7jh48CCef/55DBo0CD169MDChQvx0ksvaesXFBRg2rRpKCkpgaOjI/z9/XH8+HHtdomIiKh9MzrUAMD8+fMxf/58vfNqg0qto0ePGrTOgIAAHD9+vMH5H3/8saHNozqsrKywcuVKnfuL2iMeh7/wWGjwOGjwOGjwOPzFXI+F0YPvEREREZkivtCSiIiIJIGhhoiIiCSBoYaIiIgkgaGGiIiIJIGhhoiIiCSBocbMxcfH48EHH4S9vT26d++OiRMn4sKFC40uc/ToUchksnrT+fPnW6nVLS8uLq7e/jg7Oze6zLFjx+Dr6wtra2vce++92Lx5cyu19u7q1auX3t/v7eNE3U4q50NaWhrCwsLg6uoKmUyGffv26cwXQiAuLg6urq6wsbHByJEjcfbs2SbXu3fvXvTv3x9WVlbo378/Pv3007u0By2jseNw69YtvPTSSxg4cCA6deoEV1dXzJgxA7/++muj60xMTNR7jty8efMu782daeqcmDlzZr198vf3b3K9UjonAOj93cpkMrz++usNrtNUzwmGGjN37NgxREdH4/jx40hNTUV1dTVCQkJQUVHR5LIXLlyASqXSTn369GmFFt893t7eOvtz5syZBuvm5uZi7NixCAoKQlZWFv75z3/iH//4B/bu3duKLb47Tp06pXMcUlNTAQB/+9vfGl3O3M+HiooKDB48GO+8847e+f/617+wfv16vPPOOzh16hScnZ0RHByM8vLyBtf57bffIiIiApGRkfjhhx8QGRmJKVOm4MSJE3drN+5YY8fhxo0b+P7777F8+XJ8//33UCqVuHjxIh5//PEm1+vg4KBzfqhUKlhbW9+NXWgxTZ0TAPDYY4/p7FNKSkqj65TaOQGg3u/1/fffh0wmw6RJkxpdr0meE02+WpvMSnFxsQAgjh071mCdI0eOCADi//7v/1qvYXfZypUrxeDBgw2u/+KLL4p+/frplD3zzDPC39+/hVvW9hYuXCh69+4tampq9M6X4vkAQHz66afazzU1NcLZ2VmsXbtWW3bz5k2hUCjE5s2bG1zPlClTxGOPPaZTNmbMGDF16tQWb/PdUPc46HPy5EkBQFy5cqXBOtu3bxcKhaJlG9fK9B2LqKgoMWHCBKPW0x7OiQkTJohHHnmk0Tqmek6wp0Ziat+p1aVLlybrDhkyBC4uLnj00Udx5MiRu920uy4nJweurq7w9PTE1KlTcenSpQbrfvvttwgJCdEpGzNmDL777jvcunXrbje11VRVVWHnzp2YPXt2k2+ml9r5cLvc3FwUFRXp/M6trKwwYsQIZGRkNLhcQ+dJY8uYm9LSUshkMnTu3LnRetevX4eHhwfc3Nwwfvx4ZGVltU4D77KjR4+ie/fuuP/++/H3v/8dxcXFjdaX+jnx22+/Yf/+/ZgzZ06TdU3xnGCokRAhBBYtWoRhw4ZhwIABDdZzcXHB1q1bsXfvXiiVSvTt2xePPvoo0tLSWrG1LcvPzw87duzAgQMH8N5776GoqAiBgYG4du2a3vpFRUVwcnLSKXNyckJ1dTVKSkpao8mtYt++ffj9998xc+bMButI8Xyoq6ioCAD0/s5r5zW0nLHLmJObN29iyZIlePLJJxt9E3O/fv2QmJiIzz//HElJSbC2tsbDDz+MnJycVmxtywsNDcVHH32Ew4cPY926dTh16hQeeeQRVFZWNriM1M+JDz74APb29ggPD2+0nqmeE8169xOZpgULFuDHH3/EN99802i9vn37om/fvtrPAQEByM/PxxtvvIHhw4ff7WbeFaGhodp/Dxw4EAEBAejduzc++OADLFq0SO8ydXsuxJ9vDGmqR8OcbNu2DaGhoXB1dW2wjhTPh4bo+5039ftuzjLm4NatW5g6dSpqamqwcePGRuv6+/vr3ED78MMPw8fHB2+//Tbeeuutu93UuyYiIkL77wEDBmDo0KHw8PDA/v37G/1Sl+o5AQDvv/8+nnrqqSbvjTHVc4I9NRLx3HPP4fPPP8eRI0fg5uZm9PL+/v5tnrBbUqdOnTBw4MAG98nZ2bneX1bFxcXo2LEjunbt2hpNvOuuXLmCr7/+GnPnzjV6WamdD7VPwun7ndf9q7vucsYuYw5u3bqFKVOmIDc3F6mpqY320ujToUMHPPjgg5I6RwBNr6WHh0ej+yXVcwIA0tPTceHChWb9P8NUzgmGGjMnhMCCBQugVCpx+PBheHp6Nms9WVlZcHFxaeHWtZ3KykpkZ2c3uE8BAQHap4JqHTx4EEOHDoWFhUVrNPGu2759O7p3745x48YZvazUzgdPT084Ozvr/M6rqqpw7NgxBAYGNrhcQ+dJY8uYutpAk5OTg6+//rpZIV4IgdOnT0vqHAGAa9euIT8/v9H9kuI5UWvbtm3w9fXF4MGDjV7WZM6JtrtHmVrCs88+KxQKhTh69KhQqVTa6caNG9o6S5YsEZGRkdrPb775pvj000/FxYsXxU8//SSWLFkiAIi9e/e2xS60iMWLF4ujR4+KS5cuiePHj4vx48cLe3t7cfnyZSFE/WNw6dIlYWtrK55//nlx7tw5sW3bNmFhYSH27NnTVrvQotRqtejZs6d46aWX6s2T6vlQXl4usrKyRFZWlgAg1q9fL7KysrRP9axdu1YoFAqhVCrFmTNnxLRp04SLi4soKyvTriMyMlIsWbJE+/m///2vkMvlYu3atSI7O1usXbtWdOzYURw/frzV989QjR2HW7duiccff1y4ubmJ06dP6/w/o7KyUruOuschLi5OfPXVV+KXX34RWVlZYtasWaJjx47ixIkTbbGLBmvsWJSXl4vFixeLjIwMkZubK44cOSICAgJEjx492tU5Uau0tFTY2tqKTZs26V2HuZwTDDVmDoDeafv27do6UVFRYsSIEdrPr732mujdu7ewtrYW99xzjxg2bJjYv39/6ze+BUVERAgXFxdhYWEhXF1dRXh4uDh79qx2ft1jIIQQR48eFUOGDBGWlpaiV69eDf7HbI4OHDggAIgLFy7UmyfV86H20fS6U1RUlBBC81j3ypUrhbOzs7CyshLDhw8XZ86c0VnHiBEjtPVrffLJJ6Jv377CwsJC9OvXz+TDXmPHITc3t8H/Zxw5ckS7jrrHISYmRvTs2VNYWloKR0dHERISIjIyMlp/54zU2LG4ceOGCAkJEY6OjsLCwkL07NlTREVFiby8PJ11SP2cqLVlyxZhY2Mjfv/9d73rMJdzQibEn3dHEhEREZkx3lNDREREksBQQ0RERJLAUENERESSwFBDREREksBQQ0RERJLAUENERESSwFBDREREksBQQ0RERJLAUENERESSwFBDREREksBQQ0RERJLw/wESOCdG4umWpgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history['accuracy']\n",
    "loss = history['loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "plt.title('Training accuracies')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.title('Training losses')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try the model on a test sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'The United States might collapsez .'.lower().split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the sentence words to indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_word_idxs = torch.tensor([word2idx.get(word,1) for word in sentence])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The indices. Note the 1 at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence ['the', 'united', 'states', 'might', 'collapsez', '.']\n",
      "Sentence word indexes tensor([358640, 373606, 343335, 245002,      1,    873])\n"
     ]
    }
   ],
   "source": [
    "print('Sentence', sentence)\n",
    "print('Sentence word indexes', sentence_word_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the chunks. Call the variable `sent_chunk_predictions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_chunk_predictions = model1(sentence_word_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 23])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_chunk_predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated probabilities of the first chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.0947e-13, 2.2619e-07, 3.1126e-05, 3.6914e-10, 1.9925e-08, 3.5169e-06,\n",
       "        9.9991e-01, 4.0391e-06, 4.8669e-08, 8.0924e-07, 9.3036e-17, 4.1477e-10,\n",
       "        1.1872e-09, 4.8793e-09, 1.6313e-09, 7.5198e-11, 3.8493e-07, 6.7904e-09,\n",
       "        8.2655e-14, 7.8450e-10, 9.5275e-09, 2.9464e-10, 5.0640e-05],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(sent_chunk_predictions[0], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6, 16, 16, 11, 21, 22])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(F.softmax(sent_chunk_predictions, dim=-1), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply argmax to select the chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the: B-NP\n",
      "united: I-NP\n",
      "states: I-NP\n",
      "might: B-VP\n",
      "collapsez /ukn: I-VP\n",
      ".: O\n"
     ]
    }
   ],
   "source": [
    "for word_nbr, chunk_predictions in enumerate(sent_chunk_predictions):\n",
    "    if int(sentence_word_idxs[word_nbr]) in idx2word:\n",
    "        print(idx2word[int(sentence_word_idxs[word_nbr])], end=': ')\n",
    "    else:\n",
    "        print(sentence[word_nbr], '/ukn', end=': ')\n",
    "    print(idx2chunk.get(int(torch.argmax(F.softmax(chunk_predictions, dim=-1), dim=-1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'form': 'Rockwell', 'pos': 'NNP', 'chunk': 'B-NP'},\n",
       "  {'form': 'said', 'pos': 'VBD', 'chunk': 'B-VP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'agreement', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'calls', 'pos': 'VBZ', 'chunk': 'B-VP'},\n",
       "  {'form': 'for', 'pos': 'IN', 'chunk': 'B-SBAR'},\n",
       "  {'form': 'it', 'pos': 'PRP', 'chunk': 'B-NP'},\n",
       "  {'form': 'to', 'pos': 'TO', 'chunk': 'B-VP'},\n",
       "  {'form': 'supply', 'pos': 'VB', 'chunk': 'I-VP'},\n",
       "  {'form': '200', 'pos': 'CD', 'chunk': 'B-NP'},\n",
       "  {'form': 'additional', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'so-called', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'shipsets', 'pos': 'NNS', 'chunk': 'I-NP'},\n",
       "  {'form': 'for', 'pos': 'IN', 'chunk': 'B-PP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'planes', 'pos': 'NNS', 'chunk': 'I-NP'},\n",
       "  {'form': '.', 'pos': '.', 'chunk': 'O'}]]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences = read_sentences(test_file)\n",
    "test_dict = split_rows(test_sentences, column_names)\n",
    "test_dict[1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the ${X}$ and ${Y}$ sequences of symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test: ['rockwell', 'said', 'the', 'agreement', 'calls', 'for', 'it', 'to', 'supply', '200', 'additional', 'so-called', 'shipsets', 'for', 'the', 'planes', '.']\n",
      "Y_test ['B-NP', 'B-VP', 'B-NP', 'I-NP', 'B-VP', 'B-SBAR', 'B-NP', 'B-VP', 'I-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'O']\n"
     ]
    }
   ],
   "source": [
    "X_test_symbs, Y_test_symbs = build_sequences(test_dict, key_x='form', key_y='chunk')\n",
    "print('X_test:', X_test_symbs[1])\n",
    "print('Y_test', Y_test_symbs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the ${X}$ symbol sequence into an index sequence and pad it. Call the results `X_test_idx` and `X_test_padded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_idx = []\n",
    "for x in X_test_symbs:\n",
    "    X_test_idx.append([word2idx.get(w,1) for w in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_idx = map(torch.LongTensor, X_test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_padded = pad_sequence(X_test_idx, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_padded: tensor([311438, 316957, 358640,  48789,  90494, 152124, 194623, 362305, 349553,\n",
      "         17495,  46648, 337426,      1, 152124, 358640, 287224,    873,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0])\n"
     ]
    }
   ],
   "source": [
    "print('X_test_padded:', X_test_padded[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2012, 70])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_padded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the chunks. Call the result `Y_test_hat_probs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_hat_probs = model1(X_test_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions tensor([[-16.7939,  -5.0272,  -5.9898,  ...,  -4.7774,  -7.0697,  -2.3619],\n",
      "        [-18.1720,  -9.3979,  -3.7579,  ...,  -8.6196,  -4.2140,   0.7232],\n",
      "        [-20.6053,  -6.3561,  -6.1820,  ...,  -8.2148,  -7.7346,   0.1120],\n",
      "        ...,\n",
      "        [ -8.7729,  -1.4440,  -3.0707,  ..., -11.8513,  -4.4330,   5.8205],\n",
      "        [ -8.1734,  -1.2796,  -2.9701,  ..., -11.4667,  -4.2742,   5.4930],\n",
      "        [ -7.5886,  -1.1247,  -2.9150,  ..., -11.2079,  -4.2072,   5.3072]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print('Predictions', Y_test_hat_probs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_hat_probs = F.softmax(Y_test_hat_probs, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now predict the whole test set and we store the results in each dictionary with the key `pchunk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent, y_hat_probs in zip(test_dict, Y_test_hat_probs):\n",
    "    sent_len = len(sent)\n",
    "    y_hat_probs = y_hat_probs[:sent_len]\n",
    "    # y_hat = torch.argmax(y_hat_probs, dim=-1) # This statement sometimes predicts 0 (the padding symbol)\n",
    "    y_hat = torch.argmax(y_hat_probs[:, 1:], dim=-1) + 1 # Never predicts 0\n",
    "    for word, ner_hat in zip(sent, y_hat):\n",
    "        word['pchunk'] = idx2chunk.get(int(ner_hat)) \n",
    "        if word['pchunk'] == None:\n",
    "            print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sentence example: `chunk` is the hand annotation and `pchunk` is the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'form': 'Rockwell', 'pos': 'NNP', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'said', 'pos': 'VBD', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'agreement', 'pos': 'NN', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'calls', 'pos': 'VBZ', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'for', 'pos': 'IN', 'chunk': 'B-SBAR', 'pchunk': 'B-SBAR'},\n",
       " {'form': 'it', 'pos': 'PRP', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'to', 'pos': 'TO', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'supply', 'pos': 'VB', 'chunk': 'I-VP', 'pchunk': 'I-VP'},\n",
       " {'form': '200', 'pos': 'CD', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'additional', 'pos': 'JJ', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'so-called', 'pos': 'JJ', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'shipsets', 'pos': 'NNS', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'for', 'pos': 'IN', 'chunk': 'B-PP', 'pchunk': 'B-PP'},\n",
       " {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'planes', 'pos': 'NNS', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': '.', 'pos': '.', 'chunk': 'O', 'pchunk': 'O'}]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the test set in a file to evaluate the performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['form', 'pos', 'chunk', 'pchunk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(file, corpus_dict, column_names):\n",
    "    \"\"\"\n",
    "    Saves the corpus in a file\n",
    "    :param file:\n",
    "    :param corpus_dict:\n",
    "    :param column_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    with open(file, 'w', encoding='utf8') as f_out:\n",
    "        i += 1\n",
    "        for sentence in corpus_dict:\n",
    "            sentence_lst = []\n",
    "            for row in sentence:\n",
    "                items = map(lambda x: row.get(x, '_'), column_names)\n",
    "                sentence_lst += ' '.join(items) + '\\n'\n",
    "            sentence_lst += '\\n'\n",
    "            f_out.write(''.join(sentence_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = 'test_model1.out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(outfile, test_dict, column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9033327806333941"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = open(outfile, encoding='utf8').read().splitlines()\n",
    "res = conlleval.evaluate(lines)\n",
    "chunker_score = res['overall']['chunks']['evals']['f1']\n",
    "chunker_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results may slightly vary depending on the run\n",
    "# 0.8650974227443842 lstm nontrainable 15 epochs\n",
    "# 0.8579701751845953 lstm trainable 15 epochs\n",
    "# 0.9015216169521867 lstm bidi nontrainable 15 epochs\n",
    "# 0.9000310655483068 lstm bidi trainable 15 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will carry out experiments with two different recurrent networks: RNN and LSTM. You will also try at least one set of parameters per network, i.e. two experiments, one with a RNN and one with a LSTM. To run a RNN, just replace the LSTM class with RNN. As baseline, a simple solution you consider a starting point, please report the baseline figures from CoNLL 2000: https://aclanthology.org/W00-0726.pdf. \n",
    "\n",
    "In your report, you will present your results in a table like this one:\n",
    "\n",
    "|Method|Parameters|Score|\n",
    "|------|-----|-----|\n",
    "|Baseline|  xx | xx |\n",
    "|RNN|  xx |xx |\n",
    "|RNN |  xx |xx |\n",
    "|LSTM |  xx |xx |\n",
    "|LSTM |  xx |xx |\n",
    "|  Akbik et al.|  xx|xx |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Turning in your assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now your are done with the program. To complete this assignment, you will:\n",
    "1. Write a short individual report on your program. You will describe the architecture your used the different experiments you carried out and your results.\n",
    "2. Read the article, <a href=\"https://www.aclweb.org/anthology/C18-1139\"><i>Contextual String Embeddings for Sequence Labeling</i></a> by Akbik et al. (2018) and outline the main differences between their system and yours. A LSTM is a type of recurrent neural network, while CRF is a sort of beam search. You will tell the performance they reach on the corpus you used in this laboratory.\n",
    "\n",
    "Submit your report as well as your notebook (for archiving purposes) to Canvas: https://canvas.education.lu.se/. To write your report, you can either\n",
    "1. Write directly your text in Canvas, or\n",
    "2. Use Latex and Overleaf (www.overleaf.com). This will probably help you structure your text. You will then upload a PDF file in Canvas.\n",
    "\n",
    "The submission deadline is October 13, 2023."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "b97b11a820675205aae8f1d7f2a3f22bbd3a2c30189f44042310baf5b4cd1987"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
