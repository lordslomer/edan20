{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment #4: Extracting syntactic groups using recurrent networks\n",
    "Author: Pierre Nugues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will create a system to extract syntactic groups from a text. You will apply it to the CoNLL 2000 dataset. You will train your models with PyTorch.\n",
    "\n",
    "Be aware that in PyTorch, the data matrices, by default, have an unconventional ordering with recurrent networks. To have a batch ordering similar to what we saw during the course, you must use the `batch_first=True` argument. See here https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_sequence.html and https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
    "\n",
    "Before you start the assignment, please run the prerequisites from the prerequistites notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objectives of this assignment are to:\n",
    "* Write a program to detect partial syntactic structures called groups or chunks\n",
    "* Understand the principles of supervised machine learning techniques applied to language processing\n",
    "* Write a short report of 2 to 3 pages on the assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This instruction may solve installation conflicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import conlleval\n",
    "import math \n",
    "import functools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeds\n",
    "Making things reproduceable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2cd830d1eb0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "np.random.seed(1234)\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "LSTM_HIDDEN_DIM = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to adjust the paths to load the datasets from your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'corpus/train.txt'\n",
    "test_file = 'corpus/test.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now convert the dataset in a Python data structure. Read the functions below to load the datasets. They store the corpus in a list of sentences. Each sentence is a list of rows, where each row is a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sentences(file):\n",
    "    \"\"\"\n",
    "    Creates a list of sentences from the corpus\n",
    "    Each sentence is a string\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    f = open(file).read().strip()\n",
    "    sentences = f.split('\\n\\n')\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_rows(sentences, column_names):\n",
    "    \"\"\"\n",
    "    Creates a list of sentence where each sentence is a list of lines\n",
    "    Each line is a dictionary of columns\n",
    "    :param sentences:\n",
    "    :param column_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    new_sentences = []\n",
    "    for sentence in sentences:\n",
    "        rows = sentence.split('\\n')\n",
    "        sentence = [dict(zip(column_names, row.split())) for row in rows]\n",
    "        new_sentences.append(sentence)\n",
    "    return new_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CoNLL 2000 files have three columns: The wordform, `form`, its part of speech, `pos`, and the tag denoting the syntactic group also called the chunk tag, `chunk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['form', 'pos', 'chunk']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the corpus as a list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'form': 'He', 'pos': 'PRP', 'chunk': 'B-NP'},\n",
       "  {'form': 'reckons', 'pos': 'VBZ', 'chunk': 'B-VP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'current', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'account', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'deficit', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'will', 'pos': 'MD', 'chunk': 'B-VP'},\n",
       "  {'form': 'narrow', 'pos': 'VB', 'chunk': 'I-VP'},\n",
       "  {'form': 'to', 'pos': 'TO', 'chunk': 'B-PP'},\n",
       "  {'form': 'only', 'pos': 'RB', 'chunk': 'B-NP'},\n",
       "  {'form': '#', 'pos': '#', 'chunk': 'I-NP'},\n",
       "  {'form': '1.8', 'pos': 'CD', 'chunk': 'I-NP'},\n",
       "  {'form': 'billion', 'pos': 'CD', 'chunk': 'I-NP'},\n",
       "  {'form': 'in', 'pos': 'IN', 'chunk': 'B-PP'},\n",
       "  {'form': 'September', 'pos': 'NNP', 'chunk': 'B-NP'},\n",
       "  {'form': '.', 'pos': '.', 'chunk': 'O'}]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences = read_sentences(train_file)\n",
    "train_dict = split_rows(train_sentences, column_names)\n",
    "train_dict[10:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_file = 'corpus/glove.6B.100d.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the function below that reads GloVe embeddings and store them in a dictionary, where the keys will be the words and the values, the embedding vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_embeddings(file):\n",
    "    \"\"\"\n",
    "    Return the embeddings in the from of a dictionary\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    embeddings = {}\n",
    "    glove = open(file, encoding='utf8')\n",
    "    for line in glove:\n",
    "        values = line.strip().split()\n",
    "        word = values[0]\n",
    "        vector = np.array(values[1:], dtype='float32')\n",
    "        embeddings[word] = vector\n",
    "    glove.close()\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read the embeddings\n",
    "embeddings_dict = read_embeddings(embedding_file)\n",
    "embedded_words = sorted(list(embeddings_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# words in embedding dictionary: 400000'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'# words in embedding dictionary: {}'.format(len(embedded_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chording',\n",
       " 'chordoma',\n",
       " 'chordophones',\n",
       " 'chords',\n",
       " 'chore',\n",
       " 'chorea',\n",
       " 'chorene',\n",
       " 'choreograph',\n",
       " 'choreographed',\n",
       " 'choreographer']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_words[100000:100010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.51973,  1.0395 ,  0.20924,  0.16285,  0.7209 ,  0.81524,\n",
       "       -0.34641, -0.76654, -0.49576,  0.24634,  0.44094,  0.37701,\n",
       "       -0.16396,  0.2775 ,  0.16563,  0.43869, -1.0887 ,  0.12663,\n",
       "        0.66916,  0.3578 ], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dict['chords'][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a cosine similarity, write a `closest(target_word, embeddings, count=10)` that computes the 10 closest words to the words _table_, _france_, and _sweden_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest2(target_word, embeddings, count=10):\n",
    "  c_s = []\n",
    "  tar = embeddings[target_word]\n",
    "  tar_len = np.sqrt(np.sum(tar**2))\n",
    "  for word in embedded_words:\n",
    "    vec = embeddings[word]\n",
    "    dot = np.dot(vec,tar)\n",
    "    vec_len = np.sqrt(np.sum(vec**2))\n",
    "    c_s.append((word,dot/(vec_len*tar_len)))\n",
    "  c_s = sorted(c_s, key=lambda x: -x[1])[:count]\n",
    "  return [tup[0] for tup in c_s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['france',\n",
       " 'belgium',\n",
       " 'french',\n",
       " 'britain',\n",
       " 'spain',\n",
       " 'paris',\n",
       " 'germany',\n",
       " 'italy',\n",
       " 'europe',\n",
       " 'netherlands']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest2('france', embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sweden',\n",
       " 'denmark',\n",
       " 'norway',\n",
       " 'finland',\n",
       " 'netherlands',\n",
       " 'austria',\n",
       " 'switzerland',\n",
       " 'germany',\n",
       " 'swedish',\n",
       " 'belgium']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest2('sweden', embeddings_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the ${X}$ and ${Y}$ Lists of Symbols from the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each sentence, you will build an input sequence, $\\mathbf{x}$, corresponding to the words and an output one, $\\mathbf{y}$, corresponding to the chunk tags.\n",
    "\n",
    "Write a `build_sequences(corpus_dict, key_x='form', key_y='chunk', tolower=True)` function that, for each sentence, returns the $\\mathbf{x}$ and $\\mathbf{y}$ lists of symbols consisting of words and chunk tags. Set the words in lower case if `tolower` is true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the 11th sentence of the training set, you should have:<br/>\n",
    "`x = ['he',  'reckons',  'the',  'current',  'account',  'deficit',  'will',  'narrow',  'to',  'only',  '#',  '1.8',  'billion',  'in',  'september',  '.']`\n",
    "\n",
    "`y = ['B-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sequences(corpus_dict, key_x='form', key_y='pos', tolower=True):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for sentence in corpus_dict:\n",
    "      sen_x = []\n",
    "      sen_y = []\n",
    "      for word_dic in sentence:\n",
    "        word = word_dic[key_x]\n",
    "        if tolower:\n",
    "          word = word.lower()\n",
    "        sen_x.append(word)\n",
    "        sen_y.append(word_dic[key_y])\n",
    "      X.append(sen_x)\n",
    "      Y.append(sen_y)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_symbs, Y_train_symbs = build_sequences(train_dict, key_x='form', key_y='chunk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', 'reckons', 'the', 'current', 'account', 'deficit', 'will', 'narrow', 'to', 'only', '#', '1.8', 'billion', 'in', 'september', '.']\n"
     ]
    }
   ],
   "source": [
    "print(X_train_symbs[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_symbs[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a vocabulary of all the words observed in the training set as well as in GloVe. You should find 401,464 different words. You will proceed in two steps.\n",
    "\n",
    "First extract the list of unique words `words` from the CoNLL training set and the list of chunk tags, `chunks`. You will sort them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = sorted(list(set(sum(X_train_symbs,[]))))\n",
    "chunks = sorted(list(set(sum(Y_train_symbs, []))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words seen in training corpus: 17258\n",
      "# Chunks tags seen: 22\n"
     ]
    }
   ],
   "source": [
    "print('# words seen in training corpus:', len(words))\n",
    "print('# Chunks tags seen:', len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['casinos',\n",
       " 'caspita',\n",
       " 'caspita-brand',\n",
       " 'cassettes',\n",
       " 'cast',\n",
       " 'castigated',\n",
       " 'castigating',\n",
       " 'castillo',\n",
       " 'casting',\n",
       " 'castro-medellin']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[4000:4010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-ADJP',\n",
       " 'B-ADVP',\n",
       " 'B-CONJP',\n",
       " 'B-INTJ',\n",
       " 'B-LST',\n",
       " 'B-NP',\n",
       " 'B-PP',\n",
       " 'B-PRT',\n",
       " 'B-SBAR',\n",
       " 'B-UCP']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, merge the list of unique CoNLL words with the words in the embeddings file. You will sort this list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_words = sorted(list(set(embedded_words+words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words in the vocabulary: embeddings and corpus: 401464\n"
     ]
    }
   ],
   "source": [
    "print('# words in the vocabulary: embeddings and corpus:', len(vocabulary_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joy',\n",
       " 'joya',\n",
       " 'joyal',\n",
       " 'joyandet',\n",
       " 'joyas',\n",
       " 'joyce',\n",
       " 'joycean',\n",
       " 'joycelyn',\n",
       " 'joyces',\n",
       " 'joydeep']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_words[200000:200010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the indices `word2idx`, `chunk2idx` and inverted indices `idx2word`, `idx2chunk` for the words and the chunk tags: i.e. you will associate each word with a number. You will use index 0 for the padding symbol and 1 for unknown words. This means that your first word will start at index 2. For the chunks, you will start at index 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word = {(i+2):vocabulary_words[i] for i in range(len(vocabulary_words))}\n",
    "idx2chunk = {(i+1):chunks[i] for i in range(len(chunks))}\n",
    "word2idx = {vocabulary_words[i]:(i+2) for i in range(len(vocabulary_words))}\n",
    "chunk2idx = {chunks[i]:(i+1) for i in range(len(chunks))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('!', 2), ('!!', 3), ('!!!', 4), ('!!!!', 5), ('!!!!!', 6), ('!?', 7), ('!?!', 8), ('\"', 9), ('#', 10), ('##', 11), ('###', 12), ('#a', 13), ('#aabccc', 14), ('#b', 15), ('#c', 16), ('#cc', 17), ('#ccc', 18), ('#cccccc', 19), ('#ccccff', 20), ('#d', 21), ('#daa', 22), ('#dcdcdc', 23), ('#e', 24), ('#f', 25), ('#faf', 26)]\n"
     ]
    }
   ],
   "source": [
    "print(list(word2idx.items())[:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chunk indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-ADJP': 1, 'B-ADVP': 2, 'B-CONJP': 3, 'B-INTJ': 4, 'B-LST': 5, 'B-NP': 6, 'B-PP': 7, 'B-PRT': 8, 'B-SBAR': 9, 'B-UCP': 10, 'B-VP': 11, 'I-ADJP': 12, 'I-ADVP': 13, 'I-CONJP': 14, 'I-INTJ': 15, 'I-NP': 16, 'I-PP': 17, 'I-PRT': 18, 'I-SBAR': 19, 'I-UCP': 20, 'I-VP': 21, 'O': 22}\n"
     ]
    }
   ],
   "source": [
    "print(chunk2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a numpy matrix of dimensions $(M, N)$, where $M$ will be the size of the vocabulary: The unique words in the training set and the words in GloVe, and $N$, the dimension of the embeddings.\n",
    "The padding symbol and the unknown word symbol will be part of the vocabulary at respectively index 0 and 1. \n",
    "\n",
    "Initialize the matrix with random values with the `np.random.uniform()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add two dimensions for the padding symbol at index 0 and unknown words at index 1\n",
    "embedding_matrix = np.random.uniform(-0.05, 0.05, (len(vocabulary_words) + 2, EMBEDDING_DIM))\n",
    "# embedding_matrix = np.random.random((len(vocabulary_words) + 2, EMBEDDING_DIM))\n",
    "# embedding_matrix = np.zeros((len(vocabulary_words) + 2, EMBEDDING_DIM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of your matrix is: (401466, 100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(401466, 100)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the matrix with the GloVe embeddings when available. This means: Replace the random vector with an embedding when available. You will use the indices from the previous section. You will call `out_of_embeddings` the list of words in CoNLL, but not in the embedding list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_of_embeddings = []\n",
    "temp = set(embedded_words)\n",
    "for word in vocabulary_words:\n",
    "  idx = word2idx[word]\n",
    "  if word in temp:\n",
    "    embedding_matrix[idx] = embeddings_dict[word]\n",
    "  else:\n",
    "    out_of_embeddings.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1464"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out_of_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"y'all\",\n",
       " 'yankus',\n",
       " 'year-ago',\n",
       " 'year-before',\n",
       " 'year-earlier',\n",
       " 'year-to-date',\n",
       " 'yield-management',\n",
       " 'zaishuo',\n",
       " 'zarett',\n",
       " 'zumbrunn']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_of_embeddings[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of the padding symbol, idx 0, random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03084805,  0.01221088, -0.00622723,  0.02853586,  0.02799758,\n",
       "       -0.02274074, -0.02235357,  0.03018722,  0.04581394,  0.03759326])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of the word _table_, the GloVe values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.61453998,  0.89692998,  0.56770998,  0.39102   , -0.22437   ,\n",
       "        0.49035001,  0.10868   ,  0.27410999, -0.23833001, -0.52152997])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[word2idx['table']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of _zarett_, a word in CoNLL 2000, but not in GloVe, random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04485961, -0.01950363,  0.03356147, -0.02404349, -0.04000838,\n",
       "        0.01959841, -0.03943566, -0.01355046,  0.00896135, -0.02441297])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[word2idx['zarett']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the ${X}$ and ${Y}$ Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now create the input and output sequences with numerical indices. First, convert the \n",
    "${X}_\\text{train\\_symbs}$ and ${Y}_\\text{train\\_symbs}$ \n",
    "lists of symbols in lists of numbers using the indices you created. Call them `X_train_idx` and `Y_train_idx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_idx = []\n",
    "Y_train_idx = []\n",
    "for x, y in zip(X_train_symbs, Y_train_symbs):\n",
    "  X_train_idx.append([word2idx[w] for w in x])\n",
    "  Y_train_idx.append([chunk2idx[c] for c in y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word indices of the three first sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[107701, 189360, 358640, 291209, 193879, 388606, 143496, 362305, 353285, 56501, 328878, 126632, 187522, 364843, 148777, 152124, 326524, 454, 131007, 152124, 306232, 363097, 454, 144953, 362305, 331257, 43426, 347508, 189267, 155109, 200552, 55175, 63614, 154, 259236, 120001, 873], [97171, 269136, 358640, 143112, 262191, 219534, 154, 307829, 106548, 362305, 43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204, 43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150, 873], [88319, 54890, 304156, 372747, 349558, 152124, 344283, 174855, 72318, 139858, 88675, 358640, 97171, 154, 144970, 362305, 56361, 57639, 261034, 288933, 240241, 189360, 180283, 234487, 183252, 340448, 218722, 360423, 873]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_idx[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chunk tag indices of the three first sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 7, 6, 16, 11, 21, 21, 21, 21, 6, 16, 16, 9, 6, 16, 7, 6, 22, 1, 7, 6, 6, 22, 11, 21, 21, 6, 16, 16, 7, 6, 16, 16, 6, 16, 16, 22], [22, 7, 6, 16, 6, 16, 6, 16, 16, 7, 6, 16, 16, 16, 11, 21, 21, 21, 6, 16, 7, 6, 7, 6, 16, 16, 22], [22, 6, 11, 6, 16, 7, 6, 11, 21, 21, 7, 6, 16, 6, 16, 11, 21, 6, 16, 16, 16, 7, 6, 16, 16, 16, 6, 16, 22]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_idx[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, pad the sentences using the `pad_sequences` function. After padding, the second sentence you look like (the indices are not necessarily the same).\n",
    "```\n",
    "x = [ 97171, 269136, 358640, 143112, 262191, 219534,    154, 307829, 106548,\n",
    "        362305,  43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204,\n",
    "         43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150,    873,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0]\n",
    "y = [22,  7,  6, 16,  6, 16,  6, 16, 16,  7,  6, 16, 16, 16, 11, 21, 21, 21,\n",
    "         6, 16,  7,  6,  7,  6, 16, 16, 22,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0]\n",
    "```\n",
    "\n",
    "You will call the results `X_train_padded` and `Y_train_padded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_idx = list(map(torch.LongTensor, X_train_idx))\n",
    "Y_train_idx = list(map(torch.LongTensor, Y_train_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_padded = pad_sequence(X_train_idx, batch_first=True)\n",
    "Y_train_padded = pad_sequence(Y_train_idx, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 97171, 269136, 358640, 143112, 262191, 219534,    154, 307829, 106548,\n",
       "        362305,  43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204,\n",
       "         43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150,    873,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_padded[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([22,  7,  6, 16,  6, 16,  6, 16, 16,  7,  6, 16, 16, 16, 11, 21, 21, 21,\n",
       "         6, 16,  7,  6,  7,  6, 16, 16, 22,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_padded[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your network consisting of one embedding layer, a simple recurrent neural network, either RNN or LSTM, and a linear layer. You will initialize the embedding layer with `embedding_matrix` using `from_pretrained()`. You may try other configurations after. As number of RNN/LSTM units use 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_matrix, embedding_dim, lstm_units, nbr_classes, freeze_embs=True, num_layers=1, bidi_lstm=False):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding.from_pretrained(\n",
    "            embedding_matrix, freeze=freeze_embs, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, lstm_units, num_layers=num_layers,\n",
    "                            batch_first=True, bidirectional=bidi_lstm)\n",
    "        if not bidi_lstm:\n",
    "            self.fc = nn.Linear(lstm_units, nbr_classes)\n",
    "        else:\n",
    "            self.fc = nn.Linear(2*lstm_units, nbr_classes)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        lstm_out = F.relu(lstm_out)\n",
    "        logits = self.fc(lstm_out)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (embeddings): Embedding(401466, 100, padding_idx=0)\n",
       "  (lstm): LSTM(100, 128, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=256, out_features=23, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda')\n",
    "embedding_matrix_tensor = torch.tensor(embedding_matrix).float().to(DEVICE)\n",
    "model1 = Model(embedding_matrix_tensor, EMBEDDING_DIM, LSTM_HIDDEN_DIM, len(chunks) + 1,num_layers=1, bidi_lstm=True).to(DEVICE)\n",
    "model1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the loss `loss_fn` and optimizer `optimizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model1.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.LongTensor(X_train_padded).to(DEVICE)\n",
    "Y_train = torch.LongTensor(Y_train_padded).to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(X_train, Y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a dictionary to store the accuracy and the loss. Th exact values are difficult to compute because of the padding symbols. We include the padding symbols in the computation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:01<00:00, 217.03it/s]\n",
      "100%|██████████| 280/280 [00:01<00:00, 252.67it/s]\n",
      "100%|██████████| 280/280 [00:01<00:00, 256.19it/s]\n",
      "100%|██████████| 280/280 [00:01<00:00, 254.04it/s]\n",
      "100%|██████████| 280/280 [00:01<00:00, 256.16it/s]\n",
      "100%|██████████| 280/280 [00:01<00:00, 241.38it/s]\n",
      "100%|██████████| 280/280 [00:01<00:00, 248.89it/s]\n",
      "100%|██████████| 280/280 [00:01<00:00, 246.97it/s]\n",
      "100%|██████████| 280/280 [00:01<00:00, 236.07it/s]\n",
      "100%|██████████| 280/280 [00:01<00:00, 242.07it/s]\n",
      "100%|██████████| 280/280 [00:01<00:00, 246.98it/s]\n",
      "100%|██████████| 280/280 [00:01<00:00, 250.92it/s]\n",
      "100%|██████████| 280/280 [00:01<00:00, 251.76it/s]\n",
      "100%|██████████| 280/280 [00:01<00:00, 252.90it/s]\n",
      "100%|██████████| 280/280 [00:01<00:00, 257.43it/s]\n"
     ]
    }
   ],
   "source": [
    "history = {}\n",
    "history['accuracy'] = []\n",
    "history['loss'] = []\n",
    "\n",
    "for epoch in range(15):\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "    word_cnt = 0\n",
    "    batch_cnt = 0\n",
    "    for X_batch, Y_batch in tqdm(dataloader):\n",
    "        batch_cnt += 1\n",
    "        Y_batch_pred = model1(X_batch)\n",
    "        loss = loss_fn(Y_batch_pred.view(-1, Y_batch_pred.shape[-1]), Y_batch.view(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_accuracy += torch.sum(torch.argmax(model1(X_train), dim=-1) == Y_train).to('cpu')\n",
    "    history['accuracy'] += [train_accuracy/torch.numel(Y_train)]\n",
    "    history['loss'] += [train_loss/batch_cnt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we visualize the training curves. Ideally, we would compare them with a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history['accuracy']\n",
    "loss = history['loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "plt.title('Training accuracies')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.title('Training losses')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try the model on a test sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'The United States might collapsez .'.lower().split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the sentence words to indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_word_idxs = torch.LongTensor([word2idx.get(word,1) for word in sentence])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The indices. Note the 1 at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence ['the', 'united', 'states', 'might', 'collapsez', '.']\n",
      "Sentence word indexes tensor([358640, 373606, 343335, 245002,      1,    873])\n"
     ]
    }
   ],
   "source": [
    "print('Sentence', sentence)\n",
    "print('Sentence word indexes', sentence_word_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the chunks. Call the variable `sent_chunk_predictions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_chunk_predictions = model1(sentence_word_idxs.to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 23])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_chunk_predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated probabilities of the first chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.3885e-08, 5.6889e-06, 1.6939e-05, 2.9360e-07, 3.0381e-06, 4.2274e-06,\n",
       "        9.9900e-01, 1.3091e-04, 5.7698e-07, 5.4568e-06, 2.7081e-07, 1.0838e-06,\n",
       "        2.3282e-06, 4.5386e-07, 2.8761e-07, 4.3969e-07, 4.8680e-05, 2.7982e-07,\n",
       "        1.9228e-07, 2.9951e-08, 7.7175e-07, 4.8805e-08, 7.8257e-04],\n",
       "       device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(sent_chunk_predictions[0], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6, 16, 16, 11, 21, 22], device='cuda:0')"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(F.softmax(sent_chunk_predictions, dim=-1), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply argmax to select the chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the: B-NP\n",
      "united: I-NP\n",
      "states: I-NP\n",
      "might: B-VP\n",
      "collapsez /ukn: I-VP\n",
      ".: O\n"
     ]
    }
   ],
   "source": [
    "for word_nbr, chunk_predictions in enumerate(sent_chunk_predictions):\n",
    "    if int(sentence_word_idxs[word_nbr]) in idx2word:\n",
    "        print(idx2word[int(sentence_word_idxs[word_nbr])], end=': ')\n",
    "    else:\n",
    "        print(sentence[word_nbr], '/ukn', end=': ')\n",
    "    print(idx2chunk.get(int(torch.argmax(F.softmax(chunk_predictions, dim=-1), dim=-1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'form': 'Rockwell', 'pos': 'NNP', 'chunk': 'B-NP'},\n",
       "  {'form': 'said', 'pos': 'VBD', 'chunk': 'B-VP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'agreement', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'calls', 'pos': 'VBZ', 'chunk': 'B-VP'},\n",
       "  {'form': 'for', 'pos': 'IN', 'chunk': 'B-SBAR'},\n",
       "  {'form': 'it', 'pos': 'PRP', 'chunk': 'B-NP'},\n",
       "  {'form': 'to', 'pos': 'TO', 'chunk': 'B-VP'},\n",
       "  {'form': 'supply', 'pos': 'VB', 'chunk': 'I-VP'},\n",
       "  {'form': '200', 'pos': 'CD', 'chunk': 'B-NP'},\n",
       "  {'form': 'additional', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'so-called', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'shipsets', 'pos': 'NNS', 'chunk': 'I-NP'},\n",
       "  {'form': 'for', 'pos': 'IN', 'chunk': 'B-PP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'planes', 'pos': 'NNS', 'chunk': 'I-NP'},\n",
       "  {'form': '.', 'pos': '.', 'chunk': 'O'}]]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences = read_sentences(test_file)\n",
    "test_dict = split_rows(test_sentences, column_names)\n",
    "test_dict[1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the ${X}$ and ${Y}$ sequences of symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test: ['rockwell', 'said', 'the', 'agreement', 'calls', 'for', 'it', 'to', 'supply', '200', 'additional', 'so-called', 'shipsets', 'for', 'the', 'planes', '.']\n",
      "Y_test ['B-NP', 'B-VP', 'B-NP', 'I-NP', 'B-VP', 'B-SBAR', 'B-NP', 'B-VP', 'I-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'O']\n"
     ]
    }
   ],
   "source": [
    "X_test_symbs, Y_test_symbs = build_sequences(test_dict, key_x='form', key_y='chunk')\n",
    "print('X_test:', X_test_symbs[1])\n",
    "print('Y_test', Y_test_symbs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the ${X}$ symbol sequence into an index sequence and pad it. Call the results `X_test_idx` and `X_test_padded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_idx = []\n",
    "for x in X_test_symbs:\n",
    "    X_test_idx.append([word2idx.get(w,1) for w in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_idx = map(torch.LongTensor, X_test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_padded = pad_sequence(X_test_idx, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_padded: tensor([311438, 316957, 358640,  48789,  90494, 152124, 194623, 362305, 349553,\n",
      "         17495,  46648, 337426,      1, 152124, 358640, 287224,    873,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0])\n"
     ]
    }
   ],
   "source": [
    "print('X_test_padded:', X_test_padded[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2012, 70])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_padded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the chunks. Call the result `Y_test_hat_probs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_hat_probs = model1(X_test_padded.to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions tensor([[-8.6957, -2.5623, -2.9612,  ..., -3.9366, -5.2143,  1.4131],\n",
      "        [-8.9471, -4.6205, -1.0767,  ..., -5.5973, -0.9262,  0.9070],\n",
      "        [-8.9828, -3.2324, -2.2836,  ..., -6.0478, -6.8736,  0.3303],\n",
      "        ...,\n",
      "        [ 7.7244, -6.9224, -7.4947,  ..., -7.8967, -8.2909, -4.6580],\n",
      "        [ 8.2032, -6.2604, -7.4460,  ..., -7.1805, -7.1361, -5.3525],\n",
      "        [ 6.1771, -4.3823, -5.8477,  ..., -5.5509, -5.0506, -4.3505]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print('Predictions', Y_test_hat_probs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_hat_probs = F.softmax(Y_test_hat_probs, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now predict the whole test set and we store the results in each dictionary with the key `pchunk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent, y_hat_probs in zip(test_dict, Y_test_hat_probs):\n",
    "    sent_len = len(sent)\n",
    "    y_hat_probs = y_hat_probs[:sent_len]\n",
    "    # y_hat = torch.argmax(y_hat_probs, dim=-1) # This statement sometimes predicts 0 (the padding symbol)\n",
    "    y_hat = torch.argmax(y_hat_probs[:, 1:], dim=-1) + 1 # Never predicts 0\n",
    "    for word, ner_hat in zip(sent, y_hat):\n",
    "        word['pchunk'] = idx2chunk.get(int(ner_hat)) \n",
    "        if word['pchunk'] == None:\n",
    "            print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sentence example: `chunk` is the hand annotation and `pchunk` is the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'form': 'Rockwell', 'pos': 'NNP', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'said', 'pos': 'VBD', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'agreement', 'pos': 'NN', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'calls', 'pos': 'VBZ', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'for', 'pos': 'IN', 'chunk': 'B-SBAR', 'pchunk': 'B-SBAR'},\n",
       " {'form': 'it', 'pos': 'PRP', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'to', 'pos': 'TO', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'supply', 'pos': 'VB', 'chunk': 'I-VP', 'pchunk': 'I-VP'},\n",
       " {'form': '200', 'pos': 'CD', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'additional', 'pos': 'JJ', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'so-called', 'pos': 'JJ', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'shipsets', 'pos': 'NNS', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'for', 'pos': 'IN', 'chunk': 'B-PP', 'pchunk': 'B-PP'},\n",
       " {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'planes', 'pos': 'NNS', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': '.', 'pos': '.', 'chunk': 'O', 'pchunk': 'O'}]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the test set in a file to evaluate the performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['form', 'pos', 'chunk', 'pchunk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(file, corpus_dict, column_names):\n",
    "    \"\"\"\n",
    "    Saves the corpus in a file\n",
    "    :param file:\n",
    "    :param corpus_dict:\n",
    "    :param column_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    with open(file, 'w', encoding='utf8') as f_out:\n",
    "        i += 1\n",
    "        for sentence in corpus_dict:\n",
    "            sentence_lst = []\n",
    "            for row in sentence:\n",
    "                items = map(lambda x: row.get(x, '_'), column_names)\n",
    "                sentence_lst += ' '.join(items) + '\\n'\n",
    "            sentence_lst += '\\n'\n",
    "            f_out.write(''.join(sentence_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = 'test_model1.out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(outfile, test_dict, column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8853794364558225"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = open(outfile, encoding='utf8').read().splitlines()\n",
    "res = conlleval.evaluate(lines)\n",
    "chunker_score = res['overall']['chunks']['evals']['f1']\n",
    "chunker_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM no-bidi nontrainable 15 epochs -> 0.869983948635634\n",
    "# LSTM bidi nontrainable 15 epochs -> 0.9008833004260626\n",
    "# RNN no-bidi nontrainable 15 epochs -> 0.8576241244017172\n",
    "# RNN bidi nontrainable 15 epochs -> 0.8853794364558225\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results may slightly vary depending on the run\n",
    "# 0.8650974227443842 lstm nontrainable 15 epochs\n",
    "# 0.8579701751845953 lstm trainable 15 epochs\n",
    "# 0.9015216169521867 lstm bidi nontrainable 15 epochs\n",
    "# 0.9000310655483068 lstm bidi trainable 15 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will carry out experiments with two different recurrent networks: RNN and LSTM. You will also try at least one set of parameters per network, i.e. two experiments, one with a RNN and one with a LSTM. To run a RNN, just replace the LSTM class with RNN. As baseline, a simple solution you consider a starting point, please report the baseline figures from CoNLL 2000: https://aclanthology.org/W00-0726.pdf. \n",
    "\n",
    "In your report, you will present your results in a table like this one:\n",
    "\n",
    "|Method|Parameters|Score|\n",
    "|------|-----|-----|\n",
    "|Baseline|  xx | xx |\n",
    "|RNN|  xx |xx |\n",
    "|RNN |  xx |xx |\n",
    "|LSTM |  xx |xx |\n",
    "|LSTM |  xx |xx |\n",
    "|  Akbik et al.|  xx|xx |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Turning in your assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now your are done with the program. To complete this assignment, you will:\n",
    "1. Write a short individual report on your program. You will describe the architecture your used the different experiments you carried out and your results.\n",
    "2. Read the article, <a href=\"https://www.aclweb.org/anthology/C18-1139\"><i>Contextual String Embeddings for Sequence Labeling</i></a> by Akbik et al. (2018) and outline the main differences between their system and yours. A LSTM is a type of recurrent neural network, while CRF is a sort of beam search. You will tell the performance they reach on the corpus you used in this laboratory.\n",
    "\n",
    "Submit your report as well as your notebook (for archiving purposes) to Canvas: https://canvas.education.lu.se/. To write your report, you can either\n",
    "1. Write directly your text in Canvas, or\n",
    "2. Use Latex and Overleaf (www.overleaf.com). This will probably help you structure your text. You will then upload a PDF file in Canvas.\n",
    "\n",
    "The submission deadline is October 13, 2023."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "b97b11a820675205aae8f1d7f2a3f22bbd3a2c30189f44042310baf5b4cd1987"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
